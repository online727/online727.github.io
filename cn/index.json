[{"categories":null,"contents":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/notes/example/go/basic/introduction/","summary":"\u003c!-- A Sample Program --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eHello World\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cp\u003eA sample go program is show here.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003epackage\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;fmt\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003emessage\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003egreetMe\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;world\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003emessage\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003egreetMe\u003c/span\u003e(\u003cspan style=\"color:#a6e22e\"\u003ename\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003estring\u003c/span\u003e) \u003cspan style=\"color:#66d9ef\"\u003estring\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello, \u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ename\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;!\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eRun the program as below:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e$ go run hello.go\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Declaring Variables --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eVariables\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cp\u003e\u003cstrong\u003eNormal Declaration:\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003evar\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emsg\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003estring\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003emsg\u003c/span\u003e = \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eShortcut:\u003c/strong\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003emsg\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Declaring Constants --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eConstants\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003econst\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ePhi\u003c/span\u003e = \u003cspan style=\"color:#ae81ff\"\u003e1.618\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"Go Introduction"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.Printf(\u0026#34;At position %d, the character %s is present\\n\u0026#34;, i, val) n := 0 x := 42 for n != x { n := guess() } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/notes/example/go/basic/flow-control/","summary":"\u003c!-- Condition --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eCondition\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;sunday\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e||\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;saturday\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003erest\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e} \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;monday\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eisTired\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003egroan\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e} \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003ework\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003e_\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003edoThing\u003c/span\u003e(); \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Uh oh\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Switch --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eSwitch\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eswitch\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003ecase\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;sunday\u0026#34;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e// cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default!\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e    \u003cspan style=\"color:#66d9ef\"\u003efallthrough\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003ecase\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;saturday\u0026#34;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003erest\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003edefault\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#a6e22e\"\u003ework\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Loop --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eLoop\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ecount\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e; \u003cspan style=\"color:#a6e22e\"\u003ecount\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026lt;=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e10\u003c/span\u003e; \u003cspan style=\"color:#a6e22e\"\u003ecount\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e++\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;My counter is at\u0026#34;\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003ecount\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003eentry\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e []\u003cspan style=\"color:#66d9ef\"\u003estring\u003c/span\u003e{\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Jack\u0026#34;\u003c/span\u003e,\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;John\u0026#34;\u003c/span\u003e,\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Jones\u0026#34;\u003c/span\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ei\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eval\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003erange\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eentry\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintf\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;At position %d, the character %s is present\\n\u0026#34;\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003ei\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eval\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003en\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003ex\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e42\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003en\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ex\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003en\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eguess\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"Flow Control"},{"categories":null,"contents":" Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.Println(\u0026#34;Value is\u0026#34;, b) func getPointer () (myPointer *int) { a := 234 return \u0026amp;a a := new(int) *a = 234 Pointers point to a memory location of a variable. Go is fully garbage-collected.\nType Conversion i := 2 f := float64(i) u := uint(i) Slice slice := []int{2, 3, 4} slice := []byte(\u0026#34;Hello\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/notes/example/go/basic/types/","summary":"\u003c!-- String Type --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eStrings\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003estr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eMultiline string\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003estr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e`Multiline\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003estring`\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Number Types --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eNumbers\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cp\u003eTypical types\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003enum\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e          \u003cspan style=\"color:#75715e\"\u003e// int\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003enum\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3.\u003c/span\u003e         \u003cspan style=\"color:#75715e\"\u003e// float64\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003enum\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e3\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e4i\u003c/span\u003e     \u003cspan style=\"color:#75715e\"\u003e// complex128\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003enum\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e byte(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;a\u0026#39;\u003c/span\u003e)  \u003cspan style=\"color:#75715e\"\u003e// byte (alias for uint8)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eOther Types\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003evar\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eu\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003euint\u003c/span\u003e = \u003cspan style=\"color:#ae81ff\"\u003e7\u003c/span\u003e        \u003cspan style=\"color:#75715e\"\u003e// uint (unsigned)\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003evar\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003ep\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003efloat32\u003c/span\u003e = \u003cspan style=\"color:#ae81ff\"\u003e22.7\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e// 32-bit float\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!----------- Arrays  ------\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eArrays\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e// var numbers [5]int\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003enumbers\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e [\u003cspan style=\"color:#f92672\"\u003e...\u003c/span\u003e]\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e{\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Pointers --\u003e\n\u003cdiv class=\"note-card medium-note\"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003ePointers\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e () {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003eb\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003egetPointer\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Value is\u0026#34;\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eb\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efunc\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003egetPointer\u003c/span\u003e () (\u003cspan style=\"color:#a6e22e\"\u003emyPointer\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003ea\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e234\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#66d9ef\"\u003ereturn\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003ea\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003ea\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e new(\u003cspan style=\"color:#66d9ef\"\u003eint\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003e*\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003ea\u003c/span\u003e = \u003cspan style=\"color:#ae81ff\"\u003e234\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003ePointers point to a memory location of a variable. Go is fully garbage-collected.\u003c/p\u003e","tags":null,"title":"Basic Types"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/notes/example/go/advanced/files/","summary":"\u003c!-- Condition --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eCondition\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;sunday\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e||\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;saturday\u0026#34;\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003erest\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e} \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eday\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;monday\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e\u0026amp;\u0026amp;\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eisTired\u003c/span\u003e() {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003egroan\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e} \u003cspan style=\"color:#66d9ef\"\u003eelse\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003ework\u003c/span\u003e()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003e_\u003c/span\u003e, \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e:=\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003edoThing\u003c/span\u003e(); \u003cspan style=\"color:#a6e22e\"\u003eerr\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e!=\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003enil\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#a6e22e\"\u003efmt\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003ePrintln\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Uh oh\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"文件操作"},{"categories":null,"contents":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/notes/example/bash/basic/","summary":"\u003c!-- Variable --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eVariable\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eNAME\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;John\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eecho $NAME\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eecho \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e$NAME\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eecho \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e${\u003c/span\u003eNAME\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- Condition --\u003e\n\u003cdiv class=\"note-card \"\u003e\n    \u003cdiv class=\"item\"\u003e\n        \u003ch5 class=\"note-title\"\u003e\u003cspan\u003eCondition\u003c/span\u003e\u003c/h5\u003e\n        \n            \u003cdiv class=\"card\"\u003e\n                \u003cdiv class=\"card-body\"\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e[[\u003c/span\u003e -z \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e$string\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e]]\u003c/span\u003e; \u003cspan style=\"color:#66d9ef\"\u003ethen\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  echo \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;String is empty\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eelif\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e[[\u003c/span\u003e -n \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e$string\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e \u003cspan style=\"color:#f92672\"\u003e]]\u003c/span\u003e; \u003cspan style=\"color:#66d9ef\"\u003ethen\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  echo \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;String is not empty\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003efi\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n            \u003c/div\u003e\n        \n    \u003c/div\u003e\n\u003c/div\u003e","tags":null,"title":"Bash Variables"},{"categories":null,"contents":"See English\u0026hellip;\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/notes/probability/random-variable/discrete/","summary":"\u003cp\u003eSee English\u0026hellip;\u003c/p\u003e","tags":null,"title":"离散随机变量"},{"categories":null,"contents":"See English\u0026hellip;\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/notes/quant-greenbook/prob-theory/1-basic/","summary":"\u003cp\u003eSee English\u0026hellip;\u003c/p\u003e","tags":null,"title":"基础定义"},{"categories":null,"contents":"See English\u0026hellip;\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/notes/quant-greenbook/prob-theory/2-combinatorial/","summary":"\u003cp\u003eSee English\u0026hellip;\u003c/p\u003e","tags":null,"title":"组合数"},{"categories":null,"contents":"多层感知机 是最简单的深度网络，由多层神经元组成，每一层与它的上一层相连，从中接收输入；同时每一层也与它的下一层相连，影响当前层的神经元。本章还涉及许多基本的概念介绍，包括过拟合、欠拟合、模型选择、数值稳定性、参数初始化以及权重衰减和暂退法等正则化技术。\n1. 多层感知机 1.1 简介 在第三章中涉及了线性回归和 softmax 回归，并在线性的背景下使用 Pytorch 进行了简单实现，这两个简单的回归基于第三章中介绍的 仿射变换，即一个带有偏置项的线性变换，但是，在实际生活中，线性 是一个非常强的假设。\n我们或许有理由说一个人的年收入与其贷款是否违约具有负向线性相关性，但对于第三章章讨论的图像分类问题，就很难认为某个像素点的强度与其类别之间的关系仍是线性的。因此，我们选择构建一个深度神经网络，通过 隐藏层 的计算为我们的数据构建一种 表示，这种表示可以考虑特征之间的交互作用，在表示上，我们再建立一个线性模型用于预测可能是合适的。\n通过在网络中加入一个或多个隐藏层，配合激活函数，我们便可以克服线性模型的限制，使其能处理更普遍的函数关系。最简单的方式就是将许多全连接层堆叠在一起，每一层都输出到其上面的层，直到生成最后的输出。我们可以把前 $L-1$ 层看作表示，最后一层看作线性预测器。这种架构通常称为 多层感知机 (multilayer perceptron)，通常缩写为 MLP。一般多层感知机的架构如下图所示：\n这个多层感知机有 4 个输入，3 个输出，其隐藏层包含 5 个隐藏单元。输入层不涉及任何计算，因此，这个多层感知机中的层数为 2。由于隐藏层和输出层都是全连接的，每个输入都会影响隐藏层中的每个神经元，而隐藏层中的每个神经元又会影响输出层中的每个神经元。\n以 $\\bold{X}\\in\\mathbb{R}^{n\\times d}$ 来表示 $n$ 个样本的小批量，其中每个样本具有 $d$ 个输入特征。对于具有 $h$ 个隐藏单元的单隐藏层多层感知机，用 $\\bold{H}\\in\\mathbb{R}^{n\\times h}$ 表示隐藏层的输出，称为 隐藏表示 (hidden representations)，隐藏层变量 (hidden-layer variable) 或 隐藏变量 (hidden variable)。对于全连接的隐藏层和输出层，有隐藏层权重 $\\bold{W}^{(1)}\\in\\mathbb{R}^{d\\times h}$ 和隐藏层偏置 $\\bold{b}^{(1)}\\in\\mathbb{R}^{1\\times h}$ 以及输出层权重 $\\bold{W}^{(2)}\\in\\mathbb{R}^{h\\times q}$ 和输出层偏置 $\\bold{b}^{(2)}\\in\\mathbb{R}^{1\\times 1}$。由此便可以计算单隐藏层多层感知机的输出： $$ \\begin{align*} \\bold{H} \u0026amp;= \\bold{XW}^{(1)} + \\bold{b}^{(1)} \\cr \\bold{O} \u0026amp;= \\bold{HW}^{(2)} + \\bold{b}^{(2)} \\cr \\end{align*} $$\n但是，上述网络只是两次线性仿射变换，本质上仍是仿射变换，并未比一次线性变换带来更多的信息，我们可以证明，任意与如上网络类似的多层感知机，只需合并隐藏层，就可以产生等价的单层模型。\n那么，如何使多层感知机发挥更强的功能呢？答案是：在仿射变换之后对每个隐藏单元应用 非线性的激活函数 (activation function) $\\sigma$，激活函数的输出 $\\sigma(\\cdot)$ 称为 激活值 (activation)。此时，多层感知机的计算方式为： $$ \\begin{align*} \\bold{H} \u0026amp;= \\sigma(\\bold{XW}^{(1)} + \\bold{b}^{(1)}) \\cr \\bold{O} \u0026amp;= \\bold{HW}^{(2)} + \\bold{b}^{(2)} \\cr \\end{align*} $$\n1.2 激活函数 激活函数 (activation function) 过计算加权和并加上偏置来确定神经元是否应该被激活，将输入信号转换为输出的可微运算，大多数激活函数都是非线性的。下面简要介绍一些常见的激活函数。\n1.2.1 ReLU 修正线性单元 (Rectified linear unit，ReLU)，实现简单，同时在各种预测任务中表现良好。ReLU 提供了一种非常简单的非线性变换，对于给定元素，ReLU 函数被定义为该元素与 0 的最大值： $$ ReLU(x) = \\max(x, 0) $$\n即：ReLU 函数通过将相应的活性值设为 0，仅保留正元素并丢弃所有负元素。该函数是分段线性的。当输入为负时，ReLU 函数的导数为 0，而当输入为正时，ReLU 函数的导数为 1。注意，当输入值精确等于 0 时，ReLU 函数不可导。此时，我们默认使用左侧的导数，即当输入为 0 时导数为 0。\nPyTorch 中可以设置输入为负时，ReLU 函数的导数值。且由于 ReLU 函数倒数为常数，其可以有效缓解梯度消失、梯度爆炸问题。 ReLU 函数的诸多变体，如 参数化 ReLU (parameterized ReLU, pReLU) 也经常使用。 $$ pReLU(x) = \\max(0, x) + \\alpha\\min(0, x) $$\n1.2.2 sigmoid sigmoid 通常称为 挤压函数 (squashing function)，它将范围在 $(-\\infty,\\infty)$ 上的任意输入压缩到区间 $(0,1)$ 上的某个值： $$ sigmoid(x)=\\frac{1}{1+\\exp(-x)} $$\nsigmoid 函数是一个平滑的、可微的阈值单元近似。当我们想要将输出视作二元分类问题的概率时，sigmoid 被广泛用作输出单元上的激活函数，它可以视为 softmax 的特例。\nsigmoid 在隐藏层中已经较少使用，它在大部分时候被更简单、更容易训练的ReLU所取代。 sigmoid 函数的导数为： $$ \\frac{d}{dx}sigmoid(x)=\\frac{\\exp(-x)}{(1+\\exp(-x))^2}=sigmoid(x)(1-sigmoid(x)) $$\n1.2.3 tanh tanh (双曲正切) 函数也可以将范围在 $(-\\infty,\\infty)$ 上的任意输入压缩到区间 $(0,1)$ 上的某个值： $$ tanh(x) = \\frac{1-\\exp(-2x)}{1+\\exp(-2x)} $$\nsigmoid 和 tanh 在输入接近于 0 时都接近于线性变换，但 tanh 函数的斜率更大。 tanh 函数的导数为： $$ \\frac{d}{dx}tanh(x)=1-tanh^{2}(x) $$\n2. 实现一个多层感知机 仍使用手写数字数据集 Fashion-MNIST。\n2.1 从零实现 import torch from torch import nn from d2l import torch as d2l # 读取数据 batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) # 隐藏层个数一般设置为 2 的幂次，因为计算机的内存分配使用字节，这样方便计算。 num_inputs, num_outputs, num_hiddens = 784, 10, 256 W1 = nn.Parameter( torch.randn( num_inputs, num_hiddens, requires_grad=True ) * 0.01 ) b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True)) W2 = nn.Parameter( torch.randn( num_hiddens, num_outputs, requires_grad=True ) * 0.01 ) b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True)) params = [W1, b1, W2, b2] # 激活函数 def relu(X): a = torch.zeros_like(X) return torch.max(X, a) # 模型 def net(X): X = X.reshape((-1, num_inputs)) H = relu(X @ W1 + b1) # 这里“@”代表矩阵乘法 return (H @ W2 + b2) # 损失函数 loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) # 训练 num_epochs, lr = 10, 0.1 updater = torch.optim.SGD(params, lr=lr) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater) 2.2 简介实现 # 模型 net = nn.Sequential( nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), nn.Linear(256, 10) ) def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights) # 训练 batch_size, lr, num_epochs = 256, 0.1, 10 loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) trainer = torch.optim.SGD(net.parameters(), lr=lr) train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) ","date":"August 13, 2024","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/posts/dltorch/ch4/","summary":"\u003cp\u003e\u003cstrong\u003e多层感知机\u003c/strong\u003e 是最简单的深度网络，由多层神经元组成，每一层与它的上一层相连，从中接收输入；同时每一层也与它的下一层相连，影响当前层的神经元。本章还涉及许多基本的概念介绍，包括过拟合、欠拟合、模型选择、数值稳定性、参数初始化以及权重衰减和暂退法等正则化技术。\u003c/p\u003e\n\u003ch2 id=\"1-多层感知机\"\u003e1. 多层感知机\u003c/h2\u003e\n\u003ch3 id=\"11-简介\"\u003e1.1 简介\u003c/h3\u003e\n\u003cp\u003e在第三章中涉及了线性回归和 softmax 回归，并在线性的背景下使用 Pytorch 进行了简单实现，这两个简单的回归基于第三章中介绍的 \u003cstrong\u003e仿射变换\u003c/strong\u003e，即一个带有偏置项的线性变换，但是，在实际生活中，\u003cstrong\u003e线性\u003c/strong\u003e 是一个非常强的假设。\u003c/p\u003e\n\u003cp\u003e我们或许有理由说一个人的年收入与其贷款是否违约具有负向线性相关性，但对于第三章章讨论的图像分类问题，就很难认为某个像素点的强度与其类别之间的关系仍是线性的。因此，我们选择构建一个深度神经网络，通过 \u003cstrong\u003e隐藏层\u003c/strong\u003e 的计算为我们的数据构建一种 \u003cstrong\u003e表示\u003c/strong\u003e，这种表示可以考虑特征之间的交互作用，在表示上，我们再建立一个线性模型用于预测可能是合适的。\u003c/p\u003e\n\u003cp\u003e通过在网络中加入一个或多个隐藏层，配合激活函数，我们便可以克服线性模型的限制，使其能处理更普遍的函数关系。最简单的方式就是将许多全连接层堆叠在一起，每一层都输出到其上面的层，直到生成最后的输出。我们可以把前 $L-1$ 层看作表示，最后一层看作线性预测器。这种架构通常称为 \u003cstrong\u003e多层感知机\u003c/strong\u003e (multilayer perceptron)，通常缩写为 \u003ccode\u003eMLP\u003c/code\u003e。一般多层感知机的架构如下图所示：\u003c/p\u003e\n\u003cimg src=\"/posts/dltorch/ch4/images/MLP.png\"\n    \n        alt=\"多层感知机\"\n    \n    \n    \n    \n    \n        class=\"center\"\n    \n\u003e\n\n\u003cdiv style=\"margin-top: rem;\"\u003e\u003c/div\u003e\n\u003cp\u003e这个多层感知机有 4 个输入，3 个输出，其隐藏层包含 5 个隐藏单元。输入层不涉及任何计算，因此，这个多层感知机中的层数为 2。由于隐藏层和输出层都是全连接的，每个输入都会影响隐藏层中的每个神经元，而隐藏层中的每个神经元又会影响输出层中的每个神经元。\u003c/p\u003e\n\u003cp\u003e以 $\\bold{X}\\in\\mathbb{R}^{n\\times d}$ 来表示 $n$ 个样本的小批量，其中每个样本具有 $d$ 个输入特征。对于具有 $h$ 个隐藏单元的单隐藏层多层感知机，用 $\\bold{H}\\in\\mathbb{R}^{n\\times h}$ 表示隐藏层的输出，称为 \u003cstrong\u003e隐藏表示\u003c/strong\u003e (hidden representations)，\u003cstrong\u003e隐藏层变量\u003c/strong\u003e (hidden-layer variable) 或 \u003cstrong\u003e隐藏变量\u003c/strong\u003e (hidden variable)。对于全连接的隐藏层和输出层，有隐藏层权重 $\\bold{W}^{(1)}\\in\\mathbb{R}^{d\\times h}$ 和隐藏层偏置 $\\bold{b}^{(1)}\\in\\mathbb{R}^{1\\times h}$ 以及输出层权重 $\\bold{W}^{(2)}\\in\\mathbb{R}^{h\\times q}$ 和输出层偏置 $\\bold{b}^{(2)}\\in\\mathbb{R}^{1\\times 1}$。由此便可以计算单隐藏层多层感知机的输出：\n$$\n\\begin{align*}\n\\bold{H} \u0026amp;= \\bold{XW}^{(1)} + \\bold{b}^{(1)} \\cr\n\\bold{O} \u0026amp;= \\bold{HW}^{(2)} + \\bold{b}^{(2)} \\cr\n\\end{align*}\n$$\u003c/p\u003e","tags":["DeepLearning","Pytorch","MLP","Normalization"],"title":"第四章 多层感知机"},{"categories":null,"contents":"1. 线性回归 1.1 线性回归的基本元素 1.1.1 线性模型 线性回归，假设自变量 $\\bold{x}$ 和因变量 $y$ 之间为线性关系，其中可能包含噪声，但噪声是比较正常的，如噪声服从正态分布。\n给定一个样本 $\\bold{x}\\in\\mathbb{R}^{d}$，即具有 $d$ 个特征，将所有系数记为 $\\bold{w}\\in\\mathbb{R}^{d}$，线性回归的基本形式为： $$ \\hat{y} = \\bold{w}^{T}\\bold{x} + b $$\n矩阵形式下，$\\bold{X}\\in\\mathbb{R}^{n\\times d}$ 为所有样本的特征，此时线性回归表示为： $$ \\hat{\\bold{y}} = \\bold{Xw} + b $$\n给定训练数据集 $\\bold{X}$ 和对应标签 $\\bold{y}$，线性回归的目标就是找到一组权重向量 $\\bold{w}$ 和偏置 $b$，使得所有样本的预测误差尽可能小。\n1.1.2 损失函数 损失函数，用以度量上面提到的 “预测误差”，通常选择一个非负数作为损失，且该损失越小越好。回归问题中，最常用的损失函数为 平方误差，当样本 $i$ 的预测值为 $\\hat{y}^{(i)}$，相应真实标签为 $y^{(i)}$ 时，平方误差定义为： $$ l^{(i)}(\\bold{w}, b) = \\frac{1}{2}\\left(\\hat{y}^{(i)} - y^{(i)} \\right)^{2} $$\n$\\frac{1}{2}$ 是为了损失函数求导时常数系数为 1,不会有本质差别。\n那么，为了度量模型在整个训练集上的表现，就需要计算在整个训练集 $n$ 个样本上的损失均值 (等价于求和)： $$ L(\\bold{w}, b) = \\frac{1}{n}\\sum_{i=1}^{n}l^{(i)}(\\bold{w},b) = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{1}{2}\\left(\\bold{w}^{T}\\bold{x}^{(i)} + b - y^{(i)} \\right)^{2} $$\n此时，模型训练的目标就是寻找一组参数 $(\\bold{w}^{*},b^{*})$，以最小化所有训练样本上的总损失，即： $$ \\bold{w}^{*},b^{*} = \\argmin_{\\bold{w},b}L(\\bold{w},b) $$\n1.1.3 解析解 线性回归可以求出解析解，将偏置 $b$ 合并到权重 $\\bold{w}$ 中，最小二乘法，即可得到： $$ \\bold{w}^{*} = (\\bold{X}^{T}\\bold{X})^{-1}\\bold{X}^{T}\\bold{y} $$\n1.1.4 随机梯度下降 对于其他更复杂的模型，可能不存在解析解，那么就需要使用一些数值优化方法，以求得数值解。深度学习中常用 梯度下降法 (Gradient Decent)。梯度下降通过计算损失函数关于模型参数的导数 (此处也可称为梯度)，来更新参数。在实际中遍历整个数据集可能非常缓慢，所以我们通常每次随机抽取一小批样本计算，这种方法称为 小批量随机梯度下降 (minibatch stochastic gradient decent)。\n每次迭代，随机抽取一个小批量 $B$，计算该批次的损失均值关于参数的导数，乘以一个预先确定的正数 $\\eta$ (学习率)，并从当前参数中减去，以数学公式表示如下： $$ (\\bold{w}, b)\\leftarrow(\\bold{w}, b) - \\frac{\\eta}{|B|}\\sum_{i\\in B}\\partial_{\\bold{w}, b}l^{(i)}(\\bold{w}, b) $$\n总结：算法步骤如下：\n初始化模型参数，如随机初始化 从数据集抽取小批量样本且在负梯度方向上更新参数，并不断迭代这个步骤 对于平方损失函数，我们有： $$ \\begin{align*} \\bold{w}\u0026amp;\\leftarrow \\bold{w} - \\frac{\\eta}{|B|}\\sum_{i\\in B}\\partial_{\\bold{w}}l^{(i)}(\\bold{w}, b) = \\bold{w} - \\frac{\\eta}{|B|}\\sum_{i\\in B}\\bold{x}^{(i)}(\\bold{w}^{T}\\bold{x}^{(i)} + b - y^{(i)}) \\cr b\u0026amp;\\leftarrow b - \\frac{\\eta}{|B|}\\sum_{i\\in B}\\partial_{b}l^{(i)}(\\bold{w}, b) = b - \\frac{\\eta}{|B|}\\sum_{i\\in B}(\\bold{w}^{T}\\bold{x}^{(i)} + b - y^{(i)}) \\end{align*} $$\n批量大小 $B$ (batch size) 和学习率 $\\eta$ (learning rate) 通常是预先确定的，此类参数称为超参数 (hyperparameter)，调参 (hyperparameter tuning) 就是选择超参数的过程。这个选择过程通常是根据训练迭代的结果来调整的，训练迭代结果一般在独立的 验证数据集 (validation dataset) 上得到。\n我们的最终目标是：通过训练集的训练和验证集上参数的选择，找到一组具有比较良好泛化 (generalization) 能力的模型参数的估计值 $\\hat{\\bold{w}},\\hat{b}$，使其在没有见过的样本上也具有较小的损失。\n1.2 正态分布与平方损失 线性回归中假设观测中包含噪声，而该噪声服从正态分布，这也是为什么线性回归可以使用均方误差的原因。噪声正态分布如下式： $$ y = \\bold{w}^{T}\\bold{x}^{(i)} + b + \\epsilon, \\epsilon\\sim N(0, \\sigma^{2}) $$\n下面证明为什么可以使用均方损失。给定 $\\bold{x}$ 时 观测到 $y$ 的似然 (likelihood) 为： $$ P(y|\\bold{x}) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp\\left(-\\frac{1}{2\\sigma^{2}}(y - \\bold{w}^{T}\\bold{x}^{(i)} - b)^{2} \\right) $$\n利用极大似然估计，参数 $\\bold{w}, b$ 的最优值是使整个数据集的似然最大的值，即： $$ P(\\bold{y}|\\bold{X}) = \\prod_{i=1}^{n}p(y^{(i)}|\\bold{x}^{(i)}) $$\n极大似然估计法得到的估计量称为极大似然估计量，取对数，再取负，则可以将目标变为最小化负对数似然 $-\\log P(\\bold{y}|\\bold{X})$，即： $$ -\\log P(\\bold{y}|\\bold{X}) = \\sum_{i=1}^{n}\\frac{1}{2}\\log(2\\pi\\sigma^{2}) + \\frac{1}{2\\sigma^{2}}(y^{(i)} - \\bold{w}^{T}\\bold{x}^{(i)} - b)^{2} $$\n在正态噪声的假设下，再假设 $\\sigma$ 为常数，上式即与均方误差等价。\n2. 从零开始实现线性回归 生成数据集 def synthetic_data(w, b, num_examples): \u0026#34;\u0026#34;\u0026#34;生成 y = Xw + b + 噪声\u0026#34;\u0026#34;\u0026#34; X = torch.normal(0, 1, (num_examples, len(w))) y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) return X, y.reshape((-1, 1)) true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = synthetic_data(true_w, true_b, 1000) 读取数据集，随机取一个小批量 def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) # 样本随机读取，没有特定的顺序 random.shuffle(indices) for i in range(0, num_examples, batch_size): batch_indices = torch.tensor( indices[i: min(i + batch_size, num_examples)]) yield features[batch_indices], labels[batch_indices] 初始化模型参数，正态分布初始化 w = torch.normal(0, 0.01, size=(2,1), requires_grad=True) b = torch.zeros(1, requires_grad=True) 定义模型 def linreg(X, w, b): \u0026#34;\u0026#34;\u0026#34;线性回归模型\u0026#34;\u0026#34;\u0026#34; return torch.matmul(X, w) + b 定义损失函数 def squared_loss(y_hat, y): \u0026#34;\u0026#34;\u0026#34;均方损失\u0026#34;\u0026#34;\u0026#34; return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 定义优化算法 def sgd(params, lr, batch_size): \u0026#34;\u0026#34;\u0026#34;小批量随机梯度下降\u0026#34;\u0026#34;\u0026#34; with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size param.grad.zero_() 训练 lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) # X 和 y 的小批量损失 # 因为 l 形状是 (batch_size,1)，而不是一个标量。l 中的所有元素被加到一起， # 并以此计算关于 [w, b] 的梯度 l.sum().backward() sgd([w, b], lr, batch_size) # 使用参数的梯度更新参数 with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;) 3. 线性回归的简洁实现 生成数据集 import numpy as np import torch from torch.utils import data from d2l import torch as d2l true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = d2l.synthetic_data(true_w, true_b, 1000) 读取数据集 def load_array(data_arrays, batch_size, is_train=True): \u0026#34;\u0026#34;\u0026#34;构造一个 PyTorch 数据迭代器\u0026#34;\u0026#34;\u0026#34; dataset = data.TensorDataset(*data_arrays) return data.DataLoader(dataset, batch_size, shuffle=is_train) batch_size = 10 data_iter = load_array((features, labels), batch_size) 定义模型 net 是一个 Sequential 类的实例。 Sequential 类将多个层串联在一起。 当给定输入数据时，Sequential 实例将数据传入到第一层， 然后将第一层的输出作为第二层的输入，以此类推。 # nn 是神经网络的缩写 from torch import nn net = nn.Sequential(nn.Linear(2, 1)) 初始化模型参数 在使用 net 之前，需要初始化模型参数。深度学习框架通常有预定义的方法来初始化参数，在这里，我们指定每个权重参数应该从均值为 0、标准差为 0.01 的正态分布中随机采样，偏置参数将初始化为零。 通过 net[0] 选择网络中的第一个图层，然后使用 weight.data 和 bias.data 方法访问参数，使用替换方法 normal_ 和 fill_ 来重写参数值。 net[0].weight.data.normal_(0, 0.01) net[0].bias.data.fill_(0) 定义损失函数 计算均方误差使用的是 MSELoss 类，也称为平方 $L_{2}$ 范数。默认情况下，它返回所有样本损失的平均值。 loss = nn.MSELoss() 定义优化算法 PyTorch 在 optim 模块中实现了该算法的许多变种。实例化一个 SGD 实例，指定优化的参数 (可通过 net.parameters() 从我们的模型中获得) 以及优化算法所需的超参数。小批量随机梯度下降只需要设置 lr 值，这里设置为 0.03。 trainer = torch.optim.SGD(net.parameters(), lr=0.03) 训练 num_epochs = 3 for epoch in range(num_epochs): for X, y in data_iter: l = loss(net(X) ,y) trainer.zero_grad() l.backward() trainer.step() l = loss(net(features), labels)线性模型 print(f\u0026#39;epoch {epoch + 1}, loss {l:f}\u0026#39;) 4. Softmax 回归 前述内容是应用于回归预测的线性模型，除此之外，它也可以用于分类问题。\n4.1 分类问题 在样本特征方面，与回归类似，每个样本有一个特征向量。而在预测标签方面，如预测猫、狗、鸡，一个直接的想法是选择 ${1,2,3}$，但这会为类别赋予“顺序”信息，在类别间有一定自然顺序时，这样做是可行的，如 ${婴儿，儿童，青年，老年}$，但该类问题亦可以转化为回归问题。因此，在预测标签方面，一般使用 独热编码 (one-hot encoding)。独热编码是一个具有与类别数相同个数分量的向量，类别对应的分量设为 1，其余为 0。如猫、狗、鸡可以设置为 ${(1,0,0),(0,1,0),(0,0,1)}$。\n4.2 网络架构 为了估计所有可能类别的条件概率，就需要一个多输出的模型，每个类别对应一个输出，即设置与类别个数相同的仿射函数。假设如上的例子中有 4 个特征，那么我们便需要 3 个 4 元回归方程，共 12 个参数、4 各偏置。如下我们为每个输入计算 3 个未规范化的预测 (logit) $o_{1},o_{2},o_{3}$： $$ \\begin{align*} o_{1} \u0026amp;= x_{1}w_{11} + x_{2}w_{12} + x_{3}w_{13} + x_{4}w_{14} + b_{1} \\cr o_{2} \u0026amp;= x_{1}w_{21} + x_{2}w_{22} + x_{3}w_{23} + x_{4}w_{24} + b_{2} \\cr o_{3} \u0026amp;= x_{1}w_{31} + x_{2}w_{32} + x_{3}w_{33} + x_{4}w_{34} + b_{3} \\end{align*} $$\n仍将模型表达为矩阵形式，则有 $\\bold{o=Wx+b}, W\\in\\mathbb{R}^{3\\times4}, x\\in\\mathbb{R}^{4}, b\\in\\mathbb{R}^{3}$。\n只使用一个神经层进行 softmax 回归时，输出层同时也是全连接层，其参数开销为 $O(dq)$，$d$ 是输入维度，$q$ 是输出维度，在实践中可能非常大，但有一定的方式可以把这个开销降低至 $O(dq/n)$，$n$ 为超参数，可以灵活设置，以在参数节省和模型有效性间合理权衡。\n4.3 softmax 运算 上述网络的输出是未经规范化的预测：我们没有限制它们的和为 1，也没有限制它们的值不能为负，这违背了概率公理，因此，若要将输出视为概率，我们需要保证输出非负且和为 1，且需要一个目标函数，以激励模型精准地估计概率，该属性称之为 校准 (calibration)。\nsoftmax 函数正是我们所需要的，其计算公式如下： $$ \\hat{\\bold{y}} = softmax(\\bold{o}), \\hat{y}_{j}=\\frac{\\exp (o_j)}{\\sum_k \\exp (o_k)} $$\n该函数不会改变原有的大小次序，且可导，我们认可通过下式选择最有可能的类别： $$ \\argmax_{j}\\hat{y}_{j} = \\argmax_jo_j $$\n4.4 批量样本的向量化 将上述内容结合批量，输入数据为 $\\bold{X}\\in\\mathbb{R}^{n\\times d}$，权重为 $\\bold{W}\\in\\mathbb{R}^{d\\times q}$，偏置为 $\\bold{b}\\in\\mathbb{1\\times q}$，则 softmax 可以写为： $$ \\begin{align*} \\bold{O}\u0026amp;=\\bold{XW+b} \\cr \\hat{\\bold{Y}} \u0026amp;= softmax(\\bold{O}) \\end{align*} $$\n其中，softmax 函数按行运算。\n4.5 损失函数 softmax 函数的输出给出了一个向量 $\\hat{\\bold{y}}$，可以理解为任意给定输入 $\\bold{x}$ 时每个类别的条件概率，设整个数据集 ${\\bold{X,Y}}$ 有 $n$ 个样本，索引 $i$ 的特征向量和独热标签向量分别为：$\\bold{x}^{(i)},\\bold{y}^{(i)}$，比较估计值和真实值即有： $$ P(\\bold{Y}|\\bold{X})=\\prod_{i=1}^{n}P(\\bold{y}^{(i)}|\\bold{x}^{(i)}) $$\n进行极大似然估计，最大化 $P(\\bold{Y}|\\bold{X})$，即最小化负对数似然： $$ -\\log P(\\bold{Y}|\\bold{X}) = \\sum_{i=1}^{n}-\\log P(\\bold{y}^{(i)}|\\bold{x}^{(i)}) = \\sum_{i=1^{n}}l(\\bold{y}^{(i)}, \\hat{\\bold{y}}^{(i)}) $$\n其中，对于任意标签 $\\bold{y}$ 和模型预测 $\\hat{\\bold{y}}^{(i)}$，损失函数为： $$ l(\\bold{y}^{(i)}, \\hat{\\bold{y}}^{(i)})=-\\sum_{j=1}^{q}y_{i}\\log\\hat{y}_{j} $$\n上式通常称为 交叉熵损失 (cross-entropy loss)。注意，$\\bold{y}$ 是一个长度为 $q$ 的独热编码向量，即只有一个分量为 1，则该式仅有一项，且由于概率值不大于 1，因此取对数后不大于 0，则该损失函数永远是一个非负值，预测的概率越准确，该值越接近于 0。\n将 $\\hat{y}$ 的 softmax 计算代入上式，则有： $$ \\begin{align*} l(\\bold{y}^{(i)}, \\hat{\\bold{y}}^{(i)}) \u0026amp;= -\\sum_{j=1}^{q}y_j\\log\\frac{\\exp (o_j)}{\\sum_{k=1}^{q}\\exp (o_k)} \\cr \u0026amp;= \\sum_{j=1}^{q}y_{j}\\log\\sum_{k=1}^{q}\\exp(o_k) - \\sum_{j=1}^{q}y_jo_j \\cr \u0026amp;= \\log\\sum_{k=1}^{q}\\exp(o_k) - \\sum_{j=1}^{q}y_jo_j \\end{align*} $$\n对任意为规范化的预测 $o_j$ 求导可得： $$ \\partial_{o_{j}}l(\\bold{y}^{(i)}, \\hat{\\bold{y}}^{(i)})=\\frac{\\exp(o_j)}{\\sum_{k=1}^{q}\\exp (o_k)} - y_j = softmax(\\bold{o})_j - y_j $$\n即：导数是我们 softmax 函数分配的概率与真实独热标签表示的概率之间的差。\n最后，我们的模型对任意样本的特征输出每个类别的概率，一般取其中预测概率最高的类别作为输出类别。\n5. Fashion-MNIST 数据集 Fashion-MNIST 数据集包含 10 个类别的图像，高度和宽度为 28 像素，灰度图像，通道数为 1。训练集和测试集分别包括 60000 和 10000 张图像。首先读取数据集，并定义绘图和标签转换函数。\n%matplotlib inline import torch import torchvision from torch.utils import data from torchvision import transforms from d2l import torch as d2l d2l.use_svg_display() # 通过 ToTensor 实例将图像数据从 PIL 类型变换成 32 位浮点数格式， # 并除以 255 使得所有像素的数值均在 0～1 之间 trans = transforms.ToTensor() mnist_train = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True) mnist_test = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True) def get_fashion_mnist_labels(labels): \u0026#34;\u0026#34;\u0026#34;返回 Fashion-MNIST 数据集的文本标签\u0026#34;\u0026#34;\u0026#34; text_labels = [\u0026#39;t-shirt\u0026#39;, \u0026#39;trouser\u0026#39;, \u0026#39;pullover\u0026#39;, \u0026#39;dress\u0026#39;, \u0026#39;coat\u0026#39;, \u0026#39;sandal\u0026#39;, \u0026#39;shirt\u0026#39;, \u0026#39;sneaker\u0026#39;, \u0026#39;bag\u0026#39;, \u0026#39;ankle boot\u0026#39;] return [text_labels[int(i)] for i in labels] def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): \u0026#34;\u0026#34;\u0026#34;绘制图像列表\u0026#34;\u0026#34;\u0026#34; figsize = (num_cols * scale, num_rows * scale) _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize) axes = axes.flatten() for i, (ax, img) in enumerate(zip(axes, imgs)): if torch.is_tensor(img): # 图片张量 ax.imshow(img.numpy()) else: # PIL 图片 ax.imshow(img) ax.axes.get_xaxis().set_visible(False) ax.axes.get_yaxis().set_visible(False) if titles: ax.set_title(titles[i]) return axes def get_dataloader_workers(): \u0026#34;\u0026#34;\u0026#34;使用 4 个进程来读取数据\u0026#34;\u0026#34;\u0026#34; return 4 def load_data_fashion_mnist(batch_size, resize=None): \u0026#34;\u0026#34;\u0026#34;下载 Fashion-MNIST 数据集，然后将其加载到内存中\u0026#34;\u0026#34;\u0026#34; # 通过 ToTensor 实例将图像数据从 PIL 类型变换成 32 位浮点数格式 trans = [transforms.ToTensor()] # 使用 resize 将图像调整到另一种形状 if resize: trans.insert(0, transforms.Resize(resize)) trans = transforms.Compose(trans) # 下载数据集 mnist_train = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True) mnist_test = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True) # 返回内置数据迭代器 return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()), data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers())) train_iter, test_iter = load_data_fashion_mnist(32, resize=64) for X, y in train_iter: print(X.shape, X.dtype, y.shape, y.dtype) break 6. softmax 回归从零实现 首先，加载数据并初始化模型参数：\nimport torch from IPython import display from d2l import torch as d2l batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) num_inputs = 784 # 28*28 的图像视为一维向量 num_outputs = 10 # 对应 10 个类别 W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True) # 784*10 b = torch.zeros(num_outputs, requires_grad=True) # 1*10 定义模型、softmax 函数、损失函数、分类精度、评估函数：\ndef softmax(X): X_exp = torch.exp(X) partition = X_exp.sum(1, keepdim=True) return X_exp / partition def net(X): return softmax(torch.matmul(X.reshape(-1, W.shape[0]), W) + b) def cross_entropy(y_hat, y): return - torch.log(y_hat[range(len(y_hat)), y]) def accuracy(y_hat, y): \u0026#34;\u0026#34;\u0026#34;计算预测正确的数量\u0026#34;\u0026#34;\u0026#34; if (len(y_hat.shape) \u0026gt; 1) and (y_hat.shape[1] \u0026gt; 1): y_hat = y_hat.argmax(axis=1) cmp = y_hat.type(y.dtype) == y return float(cmp.type(y.dtype).sum()) def evaluate_accuracy(net, data_iter): \u0026#34;\u0026#34;\u0026#34;计算在指定数据集上模型的精度\u0026#34;\u0026#34;\u0026#34; if isinstance(net, torch.nn.Module): net.eval() # 将模型设置为评估模式 metric = d2l.Accumulator(2) # 正确预测数、预测总数 with torch.no_grad(): for X, y in data_iter: metric.add(accuracy(net(X), y), y.numel()) return metric[0] / metric[1] 定义训练、预测过程：\ndef train_epoch_ch3(net, train_iter, loss, updater): \u0026#34;\u0026#34;\u0026#34;训练模型一个迭代周期（定义见第 3 章）\u0026#34;\u0026#34;\u0026#34; # 将模型设置为训练模式 if isinstance(net, torch.nn.Module): net.train() # 训练损失总和、训练准确度总和、样本数 metric = Accumulator(3) for X, y in train_iter: # 计算梯度并更新参数 y_hat = net(X) l = loss(y_hat, y) if isinstance(updater, torch.optim.Optimizer): # 使用 PyTorch 内置的优化器和损失函数 updater.zero_grad() l.mean().backward() updater.step() else: # 使用定制的优化器和损失函数 l.sum().backward() updater(X.shape[0]) metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) # 返回训练损失和训练精度 return metric[0] / metric[2], metric[1] / metric[2] def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): \u0026#34;\u0026#34;\u0026#34;训练模型（定义见第 3 章）\u0026#34;\u0026#34;\u0026#34; animator = d2l.Animator(xlabel=\u0026#39;epoch\u0026#39;, xlim=[1, num_epochs], ylim=[0.3, 0.9], legend=[\u0026#39;train loss\u0026#39;, \u0026#39;train acc\u0026#39;, \u0026#39;test acc\u0026#39;]) for epoch in range(num_epochs): train_metrics = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) animator.add(epoch + 1, train_metrics + (test_acc,)) train_loss, train_acc = train_metrics assert train_loss \u0026lt; 0.5, train_loss assert train_acc \u0026lt;= 1 and train_acc \u0026gt; 0.7, train_acc assert test_acc \u0026lt;= 1 and test_acc \u0026gt; 0.7, test_acc lr = 0.1 def updater(batch_size): return d2l.sgd([W, b], lr, batch_size) num_epochs = 10 train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater) def predict_ch3(net, test_iter, n=6): \u0026#34;\u0026#34;\u0026#34;预测标签（定义见第 3 章）\u0026#34;\u0026#34;\u0026#34; for X, y in test_iter: break trues = d2l.get_fashion_mnist_labels(y) preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1)) titles = [true +\u0026#39;\\n\u0026#39; + pred for true, pred in zip(trues, preds)] d2l.show_images( X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n]) predict_ch3(net, test_iter) 预测结果如下所示：\n7. softmax 回归的简洁实现 import torch from torch import nn from d2l import torch as d2l # 加载数据 batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) # 定义网络 # PyTorch 不会隐式地调整输入的形状。因此，我们在线性层前定义了展平层（flatten），来调整网络输入的形状 net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights) # 损失函数 # PyTorch 为交叉熵损失函数传递未规范化的预测，在函数中再计算 softmax 及其对数 loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) # 优化器 trainer = torch.optim.SGD(net.parameters(), lr=0.1) # 训练 num_epochs = 10 d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) 7.1 重新审视 softmax 的实现 softmax 函数中需要取 $\\exp$，在遇到较大的 $o_k$ 时，可能会导致数值 上溢，最终结果可能出现 0、inf 或 nan 值。\n我们可以通过为所有 $o_k$ 减去 $\\max(o_k)$ 来解决上溢问题，因为： $$ \\begin{align*} \\hat{y}_j \u0026amp;= \\frac{\\exp(o_j-\\max(o_k))\\exp(\\max(o_k))}{\\sum_k\\exp(o_k-\\max(o_k))\\exp(\\max(o_k))} \\cr \u0026amp;= \\frac{\\exp(o_j-\\max(o_k))}{\\sum_k\\exp(o_k-\\max(o_k))} \\end{align*} $$\n但在上述减法和规范化步骤后，可能有一些 $o_j-\\max(o_k)$ 出现较大负值，取指数后的值非常接近 0，即 下溢，则最后取对数时得到 -inf 值。\n但幸运的是，尽管我们要计算指数函数，但我们最终在计算交叉熵损失时会取它们的对数。 通过将 softmax 和交叉熵结合在一起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。 如下面的等式所示，我们避免计算 $\\exp(o_j-\\max(o_k))$，直接使用 $o_j-\\max(o_k)$： $$ \\begin{align*} \\log(\\hat{y}_j) \u0026amp;= \\log\\left(\\frac{\\exp(o_j-\\max(o_k))}{\\sum_k\\exp(o_k-\\max(o_k))}\\right) \\cr \u0026amp;= \\log(\\exp(o_j-\\max(o_k))) - \\log\\left(\\sum_k\\exp(o_k-\\max(o_k))\\right) \\cr \u0026amp;= o_j-\\max(o_k) - \\log\\left(\\sum_k\\exp(o_k-\\max(o_k))\\right) \\end{align*} $$\nPyTorch 没有将 softmax 概率传递到损失函数中， 而是在交叉熵损失函数中传递未规范化的预测，在函数中再计算 softmax 及其对数， 这是一种类似 “LogSumExp 技巧” 的聪明方式。\n","date":"July 28, 2024","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/posts/dltorch/ch3/","summary":"\u003ch2 id=\"1-线性回归\"\u003e1. 线性回归\u003c/h2\u003e\n\u003ch3 id=\"11-线性回归的基本元素\"\u003e1.1 线性回归的基本元素\u003c/h3\u003e\n\u003ch4 id=\"111-线性模型\"\u003e1.1.1 线性模型\u003c/h4\u003e\n\u003cp\u003e线性回归，假设自变量 $\\bold{x}$ 和因变量 $y$ 之间为线性关系，其中可能包含噪声，但噪声是比较正常的，如噪声服从正态分布。\u003c/p\u003e\n\u003cp\u003e给定一个样本 $\\bold{x}\\in\\mathbb{R}^{d}$，即具有 $d$ 个特征，将所有系数记为 $\\bold{w}\\in\\mathbb{R}^{d}$，线性回归的基本形式为：\n$$\n\\hat{y} = \\bold{w}^{T}\\bold{x} + b\n$$\u003c/p\u003e\n\u003cp\u003e矩阵形式下，$\\bold{X}\\in\\mathbb{R}^{n\\times d}$ 为所有样本的特征，此时线性回归表示为：\n$$\n\\hat{\\bold{y}} = \\bold{Xw} + b\n$$\u003c/p\u003e\n\u003cp\u003e给定训练数据集 $\\bold{X}$ 和对应标签 $\\bold{y}$，线性回归的目标就是找到一组权重向量 $\\bold{w}$ 和偏置 $b$，使得所有样本的预测误差尽可能小。\u003c/p\u003e\n\u003ch4 id=\"112-损失函数\"\u003e1.1.2 损失函数\u003c/h4\u003e\n\u003cp\u003e损失函数，用以度量上面提到的 “预测误差”，通常选择一个非负数作为损失，且该损失越小越好。回归问题中，最常用的损失函数为 \u003cstrong\u003e平方误差\u003c/strong\u003e，当样本 $i$ 的预测值为 $\\hat{y}^{(i)}$，相应真实标签为 $y^{(i)}$ 时，平方误差定义为：\n$$\nl^{(i)}(\\bold{w}, b) = \\frac{1}{2}\\left(\\hat{y}^{(i)} - y^{(i)} \\right)^{2}\n$$\u003c/p\u003e\n\u003cp\u003e$\\frac{1}{2}$ 是为了损失函数求导时常数系数为 1,不会有本质差别。\u003c/p\u003e\n\u003cp\u003e那么，为了度量模型在整个训练集上的表现，就需要计算在整个训练集 $n$ 个样本上的损失均值 (等价于求和)：\n$$\nL(\\bold{w}, b) = \\frac{1}{n}\\sum_{i=1}^{n}l^{(i)}(\\bold{w},b) = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{1}{2}\\left(\\bold{w}^{T}\\bold{x}^{(i)} + b - y^{(i)} \\right)^{2}\n$$\u003c/p\u003e","tags":["DeepLearning","Pytorch","LinearRegression","SoftMax"],"title":"第三章 线性神经网络"},{"categories":null,"contents":"接下来一段时间，我想自学深度学习，使用的教材为 动手学深度学习 (Pytorch 版)，该书有线上网址，且提供配套代码和相关 Python 包，详情可参见 动手学深度学习。\n第一章内容，介绍了深度学习的相关背景和应用场景，以及深度学习领域常见的术语和名词，有一定机器学习经验的人或许已比较熟悉，故不再赘述，我们直接从第二章开始。\n1. Tensor 操作和数据预处理 深度学习中的数据以张量 (tensor) 形式存储，支持 GPU 计算和 autograd 自动微分。\n张量的创建、变形、运算 (按元素 / 矩阵)、广播机制、索引、切片等均与 numpy.ndarray 类似。\n节省内存： Y = X + Y 不是原地操作，即：id(Y = X + Y) != id(Y)，会分配新的内存。 使用 Y[:] = X + Y 或 Y += X 进行原地操作以避免不必要的内存分配。 Tensor 可以与其他 Python 对象互相转换，如 tensor.numpy()。大小为 1 的张量可以转化为 Python 标量，使用 tensor.item() 或 float(tensor) 等。\n数据需要经过预处理，如填充 nan，标准化等，可以借用其他 Python 包处理后再转化为 tensor。\n2. 线性代数 标量，以小写字母 $x,y,z$ 等表示。 向量，以粗体小写字母 $\\bold{x,y,z}$ 表示，向量的维度 (形状) 代表元素个数 (向量长度)，可以使用 len(x), x.shape 获取。以列向量为默认的向量方向，例如： $$ \\begin{equation*} x = \\begin{bmatrix*} x_{1} \\cr x_{2} \\cr \\vdots \\cr x_{n} \\end{bmatrix*} \\end{equation*} $$ 矩阵，以粗体大写字母 $\\bold{X,Y,Z}$ 表示，是具有两个轴的张量。 张量 (此处指代数对象)，矩阵的拓展，一种具有更多轴的数据结构，使用特殊字体的大写字母 $X, Y, Z$ 表示。 张量的计算，与 numpy.ndarray 相同，普通的加减乘除、求和、平均、向量点积、矩阵 hadamard 积、矩阵-向量积、矩阵乘法、范数等。\n3. 微积分 3.1 导数和微分 设 $y=f(x)$，其导数被定义为： $$ f^{\u0026rsquo;}(x) = \\lim_{h\\rightarrow 0}\\frac{f(x+h) - f(x)}{h} $$\n以下符号等价： $$ f^{\u0026rsquo;}(x)=y^{\u0026rsquo;}=\\frac{dy}{dx}=\\frac{df}{dx}=\\frac{d}{dx}f(x)=Df(x)=D_{x}f(x) $$\n自行回顾求导法则。\n3.2 偏导数 将微分的思想拓展至多元函数上，设 $y=f(x_{1},\\cdots,x_{n})$ 是一个 $n$ 元函数，其关于第 $i$ 个变量 $x_{i}$ 的偏导数为： $$ \\frac{\\partial y}{\\partial x_{i}} = \\lim_{h\\rightarrow 0}\\frac{f(x_{1},\\cdots,x_{i-1},x_{i}+h,x_{i+1},\\cdots,x_{n}) - f(x_{1},\\cdots,x_{i},\\cdot,x_{n})}{h} $$\n以下表达等价： $$ \\frac{\\partial y}{\\partial x_{i}} = \\frac{\\partial f}{\\partial x_{i}} = f_{x_{i}} = f_{i} = D_{i}f = D_{x_{i}}f $$\n3.3 梯度 函数的梯度（gradient）向量，即其对所有变量的偏导数。设函数 $f: \\mathbb{R}^n \\to \\mathbb{R}$ 的输入是一个 $n$ 维向量 $\\mathbf{x} = [x_1, x_2, \\ldots, x_n]$，并且输出是一个标量。函数 $f(\\mathbf{x})$ 相对于 $\\mathbf{x}$ 的梯度是一个包含 $n$ 个偏导数的向量： $$ \\nabla_{\\mathbf{x}} f(\\mathbf{x}) = \\begin{bmatrix} \\frac{\\partial f(\\mathbf{x})}{\\partial x_1} \u0026amp; \\frac{\\partial f(\\mathbf{x})}{\\partial x_2} \u0026amp; \\cdots \u0026amp; \\frac{\\partial f(\\mathbf{x})}{\\partial x_n} \\end{bmatrix}^\\top, $$\n假设 $\\mathbf{x}$ 为 $n$ 维向量，在微分多元函数时经常使用以下规则：\n对于所有 $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$，都有 $\\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} = \\mathbf{A}^\\top$ 对于所有 $\\mathbf{A} \\in \\mathbb{R}^{n \\times m}$，都有 $\\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{A} = \\mathbf{A}$ 对于所有 $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$，都有 $\\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} = (\\mathbf{A} + \\mathbf{A}^\\top) \\mathbf{x}$ $\\nabla_{\\mathbf{x}} |\\mathbf{x}|^2 = \\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{x} = 2 \\mathbf{x}$ 同样，对于任意矩阵 $\\mathbf{X}$，都有 $\\nabla_{\\mathbf{X}} |\\mathbf{X}|_F^2 = 2 \\mathbf{X}$。\n3.4 链式法则 考虑单变量函数 $y = f(u)$ 和 $u = g(x)$， 假设都是可微的，根据链式法则： $$ \\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx} $$\n当函数具有任意数量的变量时，假设可微分函数 $y$ 有变量 $u_1, u_2, \\cdots, u_m$，其中每个可微分函数 $u_i$ 都有变量 $x_1, x_2, \\cdots, x_n$。注意，$y$ 是 $x_1, x_2, \\cdots, x_n$ 的函数。对于任意 $i = 1, 2, \\cdots, n$，链式法则给出：\n$$ \\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial u_1} \\frac{\\partial u_1}{\\partial x_i} + \\frac{\\partial y}{\\partial u_2} \\frac{\\partial u_2}{\\partial x_i} + \\cdots + \\frac{\\partial y}{\\partial u_m} \\frac{\\partial u_m}{\\partial x_i}. $$\n4. 自动微分 Pytorch 使用自动微分 (automatic differentiation) 来加快求导。 实际中，根据设计好的模型，系统会构建一个计算图 (computational graph)，以跟踪计算是哪些数据通过哪些操作组合起来产生输出，并使用自动微分进行反向传播梯度。 这里，反向传播 (backpropagate) 意味着跟踪整个计算图，填充关于每个参数的偏导数。\n当 $y$ 是标量时，可以通过链式法则反向求导输入参数的梯度，该梯度是一个与输入向量 $\\bold{x}$ 形状相同的向量。\n当 $y$ 不是标量时，向量 $\\bold{y}$ 关于 $\\bold{x}$ 的导数是一个矩阵，更高阶情况下是一个高阶张量。但当调用向量的反向传播计算时，通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里、的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。如：\nx = torch.arange(4.0) y = x * x y.sum().backward() # y.backward(torch.ones(len(x))) 如果想将某些计算移到记录的计算图之外，例如，假设 $y$ 是作为 $x$ 的函数计算的，而 $z$ 则是作为 $y$ 和 $x$ 的函数计算的。比如，我们想计算 $z$ 关于 $x$ 的梯度，但由于某种原因，希望将 $y$ 视为一个常数，并且只考虑到 $x$ 在 $y$ 被计算后发挥的作用。\n此时，可以使用 detach() 分离 $y$ 来返回一个新变量 $u$，该变量与 $y$ 具有相同的值，但丢弃计算图中如何计算 $y$ 的任何信息。换句话说，梯度不会向后流经 $u$ 到 $x$。因此，下面的反向传播函数计算 $z=u*x$ 关于 $x$ 的偏导数，$u$ 为常数。\nx.grad.zero_() y = x * x u = y.detach() z = u * x z.sum().backward() 5. 概率 单个随机变量：概率分布 多个随机变量 联合概率 (联合分布) 条件概率 (条件分布) 贝叶斯定理 边际化 (边际概率、边际分布 \u0026ndash; 全概率公式) $$P(B)=\\sum_{A}P(A,B)$$ 独立性 期望和方差 ","date":"July 27, 2024","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/posts/dltorch/ch2/","summary":"\u003cp\u003e接下来一段时间，我想自学深度学习，使用的教材为 \u003cstrong\u003e动手学深度学习 (Pytorch 版)\u003c/strong\u003e，该书有线上网址，且提供配套代码和相关 Python 包，详情可参见 \u003ca href=\"https://zh.d2l.ai/\" target=\"_blank\" rel=\"noopener\"\u003e动手学深度学习\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e第一章内容，介绍了深度学习的相关背景和应用场景，以及深度学习领域常见的术语和名词，有一定机器学习经验的人或许已比较熟悉，故不再赘述，我们直接从第二章开始。\u003c/p\u003e\n\u003ch2 id=\"1-tensor-操作和数据预处理\"\u003e1. Tensor 操作和数据预处理\u003c/h2\u003e\n\u003cp\u003e深度学习中的数据以\u003cstrong\u003e张量\u003c/strong\u003e (tensor) 形式存储，支持 GPU 计算和 autograd 自动微分。\u003c/p\u003e\n\u003cp\u003e张量的创建、变形、运算 (按元素 / 矩阵)、广播机制、索引、切片等均与 \u003ccode\u003enumpy.ndarray\u003c/code\u003e 类似。\u003c/p\u003e\n\n\n\n    \n\n\n\u003cdiv class=\"alert success\"\u003e\n    \u003cspan\u003e\u003ci data-feather=\"check-circle\"\u003e\u003c/i\u003e\u003c/span\u003e\n    \u003cspan\u003e\u003cstrong\u003e节省内存：\n\u003ccode\u003eY = X + Y\u003c/code\u003e 不是原地操作，即：\u003ccode\u003eid(Y = X + Y) != id(Y)\u003c/code\u003e，会分配新的内存。\n使用 \u003ccode\u003eY[:] = X + Y\u003c/code\u003e 或 \u003ccode\u003eY += X\u003c/code\u003e 进行原地操作以避免不必要的内存分配。\u003c/strong\u003e\u003c/span\u003e\n\u003c/div\u003e\n\n\u003cp\u003eTensor 可以与其他 Python 对象互相转换，如 \u003ccode\u003etensor.numpy()\u003c/code\u003e。大小为 1 的张量可以转化为 Python 标量，使用 \u003ccode\u003etensor.item()\u003c/code\u003e 或 \u003ccode\u003efloat(tensor)\u003c/code\u003e 等。\u003c/p\u003e\n\u003cp\u003e数据需要经过预处理，如填充 \u003ccode\u003enan\u003c/code\u003e，标准化等，可以借用其他 Python 包处理后再转化为 tensor。\u003c/p\u003e\n\u003ch2 id=\"2-线性代数\"\u003e2. 线性代数\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e标量，以小写字母 $x,y,z$ 等表示。\u003c/li\u003e\n\u003cli\u003e向量，以粗体小写字母 $\\bold{x,y,z}$ 表示，向量的维度 (形状) 代表元素个数 (向量长度)，可以使用 \u003ccode\u003elen(x), x.shape\u003c/code\u003e 获取。以列向量为默认的向量方向，例如：\n$$\n\\begin{equation*}\nx = \\begin{bmatrix*}\nx_{1} \\cr\nx_{2} \\cr\n\\vdots \\cr\nx_{n}\n\\end{bmatrix*}\n\\end{equation*}\n$$\u003c/li\u003e\n\u003cli\u003e矩阵，以粗体大写字母 $\\bold{X,Y,Z}$ 表示，是具有两个轴的张量。\u003c/li\u003e\n\u003cli\u003e张量 (此处指代数对象)，矩阵的拓展，一种具有更多轴的数据结构，使用特殊字体的大写字母 $X, Y, Z$ 表示。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e张量的计算，与 \u003ccode\u003enumpy.ndarray\u003c/code\u003e 相同，普通的加减乘除、求和、平均、向量点积、矩阵 hadamard 积、矩阵-向量积、矩阵乘法、范数等。\u003c/p\u003e","tags":["DeepLearning","Pytorch"],"title":"第二章 预备知识"},{"categories":null,"contents":"1. 摘要 投资组合的业绩归因可以分为 收益归因 和 风险归因 两个部分，而归因又可以基于净值或持仓进行。本文主要基于 持仓数据 对组合的业绩归因进行探讨。\n在组合收益归因方面，主要有以下部分：\n基于 Brinson 模型 经典版 BHB (Brinson, Hood and Beebower) 模型：将组合超额收益分解为配置收益、选股收益和交互收益 3 部分。 改进版 BF (Brinson and Fachler) 模型：引入行业超额收益，将组合超额收益分解为配置效应和选股效应两个部分。 基于多因子模型 基于行业的多因子收益归因：与自下而上的 Brinson 模型完全一致。 基于行业和风格的多因子收益归因：同时对行业和风格上的配置进行分析。 在组合风险归因方面，主要基于多因子模型：\n单一波动分解法：单独考虑每个因子，计算简单，但忽略因子之间的协同影响，且不具可加性。 边际风险分解法：将组合风险分解为因子暴露度与因子边际风险贡献的乘积，然而偏导数的概念相对模糊，指导意义不强。 三要素分解法：将风险分解为因子暴露 ($x$)、因子波动 ($\\sigma$) 和因子-组合相关系数 ($\\rho$)，对风险的分解更为透彻，更有利于投资经理对风险进行控制。 2. 基于 Brinson 模型的组合收益归因 2.1 经典 BHB 模型 BHB 模型将投资组合的超额收益率分解为 配置收益、选股收益和交互收益 三个部分，其基本框架如下图所示，其中红色渲染部分表示投资组合的超额收益。\n从行业配置的角度而言，假设 $w_{i}^{P}, w_{i}^{B}$ 分别表示投资组合和基准组合中行业 $i$ 的权重，$r_{i}^{P}, r_{i}^{B}$ 分别表示投资组合和基准组合中行业 $i$ 的收益率，那么投资组合的收益率 $R^{P}$ 和基准组合的收益率 $R^{B}$ 就可以表示为： $$ \\begin{align*} R^{P}\u0026amp;=\\sum_{i=1}^{I}w_{i}^{P}r_{i}^{P}, where\\sum_{i=1}^{I}w_{i}^{P}=1 \\cr R^{B}\u0026amp;=\\sum_{i=1}^{I}w_{i}^{B}r_{i}^{B}, where\\sum_{i=1}^{I}w_{i}^{B}=1 \\end{align*} $$\n其中，$I$ 表示行业个数。此时，投资组合超额收益 $R^{A}$ 即可表示为： $$ R^{A}=R^{P}-R^{B}=\\sum_{i=1}^{I}w_{i}^{P}r_{i}^{P} - \\sum_{i=1}^{I}w_{i}^{B}r_{i}^{B} $$\nBHB 模型将组合超额收益拆解为 配置收益 (Allocation Return, AR)、选股收益 (Selection Return, SR) 和 交互收益 (Interaction Return, IR) 三部分，即： $$ \\begin{align*} R^{A} \u0026amp;= AR+SR+IR \\cr AR \u0026amp;= \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})r_{i}^{B} \\cr SR \u0026amp;= \\sum_{i=1}^{I}w_{i}^{B}(r_{i}^{P} - r_{i}^{B}) \\cr IR \u0026amp;= R^{A} - AR - SR = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{P} - r_{i}^{B}) \\end{align*} $$\n配置收益 (AR) 等于投资组合在每个行业上的超额权重与基准行业收益率的乘积 (AR = 超额权重 × 基准行业收益率)，表示在行业内部不进行任何选股操作，持有与基准组合完全相同的行业，并通过超配收益为正、低配收益为负的行业所能够获取的超额收益。 选择收益 (SR) 等于基准权重与投资组合在行业上超额收益率的乘积 (SR = 基准权重 × 行业超额收益) ，表示在组合中保持每个行业权重与基准指数行业权重完全一致，通过行业内部的选股操作所能够获取的超额收益。 交互收益 (IR) 等于超额权重与超额收益的乘积 (IR = 超额权重 × 超额收益)，表示由配置和选股共同产生的超额收益。 本文的所有示例都是按照行业进行划分的，但 Brinson 模型的应用远不止于此。对于大类资产配置的投资者而言，他可以将收益拆解到股票、债券、现金、基金和衍生品等不同类别的大类资产配置和选择带来的收益，对于债券投资者而言，他可以将超额收益拆解到企业债、信用债、利率债、国债等不同债券类别的配置和选择带来的收益。\nBHB 模型存在的不足：\n配置效应 $AR = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})r_{i}^{B}$ 中，BHB 模型 认为超配行业绝对收益为正的行业即可获得配置效应，但若某些行业只是具有正收益，但却未能胜过基准组合，即：$0 \u0026lt; r_{i}^{B} \u0026lt; R^{B}$，那么超配此类行业显然不是完全成功的。 选择效应 $SR = \\sum_{i=1}^{I}w_{i}^{B}(r_{i}^{P} - r_{i}^{B})$ 中，当投资组合中某行业相对基准行业存在超额收益，但投资组合对该行业的权重配置低于基准权重配置，即：$w_{i}^{P} \u0026lt; w_{i}^{B}$，若仍按基准权重来计算选择效应，结果会存在一定高估。 交互效应 $IR = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{P} - r_{i}^{B})$ 的概念相对模糊，配置效应是对绝对收益为正的行业的超配、对绝对收益为负的行业的低配带来的收益，选股效应是对超额收益为正的个股的超配、对超额收益为负的个股低配带来的收益，但交互项收益部分很难从操作层面去解释，为组合的管理带来了难题。 2.2 改进版 BF 模型 BF 模型是 BHB 模型的改进版，增加了基准收益 $R^{B}$ 对配置收益的影响，基本框架如下图所示，其中仍以红色渲染部分表示投资组合的超额收益。\nBF 模型在配置效应部分的计算引入了基准收益 $R^{B}$，新的配置效应可以表示为： $$ AR_{BF}=\\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{B} - R^{B}) $$\n由于资产组合权重 $w_{i}^{P}$ 和基准组合权重 $w_{i}^{B}$ 加总均为 1，而 $R^{B}$ 是一个常数，因此： $$ \\begin{gather*} \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})R^{B} = 0 \\cr AR_{BHB} = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})r_{i}^{B} = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{B} - R^{B}) = AR_{BF} \\end{gather*} $$\n也就是说，相较于 BHB 模型而言，BF 模型中对于基准收益的引入并不会改变其配置效应的大小，二者是完全等同的，但在直观解释上 BF 模型却与投资者的实际操作更为贴合，它认为：只有超配那些相较基准指数具有正向超额收益的行业、低配那些相较基准指数具有负向超额收益的行业，才能算是成功的行业配置策略。\nBF 模型还将 BHB 模型中的选择效应和交互效应进行了合并，形成新的选股效应： $$ \\begin{align*} SR_{BF} \u0026amp;= SR_{BHB} + IR_{BHB} \\cr \u0026amp;= \\sum_{i=1}^{I}w_{i}^{B}(r_{i}^{P} - r_{i}^{B}) + \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{P} - r_{i}^{B}) \\cr \u0026amp;= \\sum_{i=1}^{I}w_{i}^{P}(r_{i}^{P} - r_{i}^{B}) \\end{align*} $$\n最后，BF 模型就将投资组合的超额收益 $R^{A}$ 分解到了对行业的配置效应 $AR$ 和行业内部的选股效应 $SR$ 两个部分： $$ \\begin{equation*} R^A_{BF} = AR_{BF} + SR_{BF} = \\sum\\limits_{i=1}^{I}(w_i^P - w_i^B)(r_i^B - R^B) + \\sum\\limits_{i=1}^{I}w_i^P(r_i^P - r_i^B) \\end{equation*} $$\n下面，我们开始\nReference: 《“星火”多因子专题报告（四） —— 基于持仓的基金业绩归因：始于 Brinson，归于 Barra》，财通证券。\n","date":"July 23, 2024","hero":"/posts/quant/multi-factors/perf-attri/images/boat.jpg","permalink":"https://online727.github.io/cn/posts/quant/multi-factors/perf-attri/","summary":"\u003ch2 id=\"1-摘要\"\u003e1. 摘要\u003c/h2\u003e\n\u003cp\u003e投资组合的业绩归因可以分为 \u003cstrong\u003e收益归因\u003c/strong\u003e 和 \u003cstrong\u003e风险归因\u003c/strong\u003e 两个部分，而归因又可以基于净值或持仓进行。本文主要基于 \u003cstrong\u003e持仓数据\u003c/strong\u003e 对组合的业绩归因进行探讨。\u003c/p\u003e\n\u003cp\u003e在组合收益归因方面，主要有以下部分：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e基于 Brinson 模型\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e经典版 BHB (Brinson, Hood and Beebower) 模型\u003c/strong\u003e：将组合超额收益分解为配置收益、选股收益和交互收益 3 部分。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e改进版 BF (Brinson and Fachler) 模型\u003c/strong\u003e：引入行业超额收益，将组合超额收益分解为配置效应和选股效应两个部分。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e基于多因子模型\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e基于行业的多因子收益归因\u003c/strong\u003e：与自下而上的 Brinson 模型完全一致。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e基于行业和风格的多因子收益归因\u003c/strong\u003e：同时对行业和风格上的配置进行分析。\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e在组合风险归因方面，主要基于多因子模型：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e单一波动分解法\u003c/strong\u003e：单独考虑每个因子，计算简单，但忽略因子之间的协同影响，且不具可加性。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e边际风险分解法\u003c/strong\u003e：将组合风险分解为因子暴露度与因子边际风险贡献的乘积，然而偏导数的概念相对模糊，指导意义不强。\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e三要素分解法\u003c/strong\u003e：将风险分解为因子暴露 ($x$)、因子波动 ($\\sigma$) 和因子-组合相关系数 ($\\rho$)，对风险的分解更为透彻，更有利于投资经理对风险进行控制。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"2-基于-brinson-模型的组合收益归因\"\u003e2. 基于 Brinson 模型的组合收益归因\u003c/h2\u003e\n\u003ch3 id=\"21-经典-bhb-模型\"\u003e2.1 经典 BHB 模型\u003c/h3\u003e\n\u003cp\u003eBHB 模型将投资组合的超额收益率分解为 \u003cstrong\u003e配置收益、选股收益和交互收益\u003c/strong\u003e 三个部分，其基本框架如下图所示，其中红色渲染部分表示投资组合的超额收益。\u003c/p\u003e\n\u003cimg src=\"/posts/quant/multi-factors/perf-attri/images/BHB.png\"\n    \n        alt=\"BNB\"\n    \n    \n    \n    \n    \n        class=\"center\"\n    \n\u003e\n\n\u003cdiv style=\"margin-top: rem;\"\u003e\u003c/div\u003e\n\u003cp\u003e从行业配置的角度而言，假设 $w_{i}^{P}, w_{i}^{B}$ 分别表示投资组合和基准组合中行业 $i$ 的权重，$r_{i}^{P}, r_{i}^{B}$ 分别表示投资组合和基准组合中行业 $i$ 的收益率，那么投资组合的收益率 $R^{P}$ 和基准组合的收益率 $R^{B}$ 就可以表示为：\n$$\n\\begin{align*}\nR^{P}\u0026amp;=\\sum_{i=1}^{I}w_{i}^{P}r_{i}^{P}, where\\sum_{i=1}^{I}w_{i}^{P}=1 \\cr\nR^{B}\u0026amp;=\\sum_{i=1}^{I}w_{i}^{B}r_{i}^{B}, where\\sum_{i=1}^{I}w_{i}^{B}=1\n\\end{align*}\n$$\u003c/p\u003e","tags":["绩效归因","多因子模型"],"title":"多因子绩效归因"},{"categories":null,"contents":"This is a sample post intended to test the followings:\nA different post author. Table of contents. Markdown content rendering. Math rendering. Emoji rendering. Markdown Syntax Rendering Headings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Inline Markdown In Table italics bold strikethrough code Code Blocks Code block with backticks html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nMath Rendering Block math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\nEmoji Rendering 🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"June 8, 2020","hero":"/posts/example/markdown-sample/hero.svg","permalink":"https://online727.github.io/cn/posts/example/markdown-sample/","summary":"\u003cp\u003eThis is a sample post intended to test the followings:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA different post author.\u003c/li\u003e\n\u003cli\u003eTable of contents.\u003c/li\u003e\n\u003cli\u003eMarkdown content rendering.\u003c/li\u003e\n\u003cli\u003eMath rendering.\u003c/li\u003e\n\u003cli\u003eEmoji rendering.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch1 id=\"markdown-syntax-rendering\"\u003eMarkdown Syntax Rendering\u003c/h1\u003e\n\u003ch2 id=\"headings\"\u003eHeadings\u003c/h2\u003e\n\u003cp\u003eThe following HTML \u003ccode\u003e\u0026lt;h1\u0026gt;\u003c/code\u003e—\u003ccode\u003e\u0026lt;h6\u0026gt;\u003c/code\u003e elements represent six levels of section headings. \u003ccode\u003e\u0026lt;h1\u0026gt;\u003c/code\u003e is the highest section level while \u003ccode\u003e\u0026lt;h6\u0026gt;\u003c/code\u003e is the lowest.\u003c/p\u003e\n\u003ch1 id=\"h1\"\u003eH1\u003c/h1\u003e\n\u003ch2 id=\"h2\"\u003eH2\u003c/h2\u003e\n\u003ch3 id=\"h3\"\u003eH3\u003c/h3\u003e\n\u003ch4 id=\"h4\"\u003eH4\u003c/h4\u003e\n\u003ch5 id=\"h5\"\u003eH5\u003c/h5\u003e\n\u003ch6 id=\"h6\"\u003eH6\u003c/h6\u003e\n\u003ch2 id=\"paragraph\"\u003eParagraph\u003c/h2\u003e\n\u003cp\u003eXerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\u003c/p\u003e","tags":null,"title":"Markdown 示例"},{"categories":null,"contents":"","date":"June 8, 2020","hero":"/posts/example/shortcodes/boat.jpg","permalink":"https://online727.github.io/cn/posts/example/shortcodes/","summary":"","tags":null,"title":"Shortcodes 示例"},{"categories":["Basic"],"contents":"This sample post tests the followings:\nCategory, sub-category nesting in the sidebar. Hero image and other images are in images folder inside this post directory. Different media rendering like image, tweet, YouTube video, Vimeo video etc. Image Sample Tweet Sample Owl bet you\u0026#39;ll lose this staring contest 🦉 pic.twitter.com/eJh4f2zncC\n\u0026mdash; San Diego Zoo Wildlife Alliance (@sandiegozoo) October 26, 2021 YouTube Video Sample Vimeo Video Sample ","date":"June 8, 2020","hero":"/posts/example/category/sub-category/rich-content/images/forest.jpg","permalink":"https://online727.github.io/cn/posts/example/category/sub-category/rich-content/","summary":"\u003cp\u003eThis sample post tests the followings:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCategory, sub-category nesting in the sidebar.\u003c/li\u003e\n\u003cli\u003eHero image and other images are in \u003ccode\u003eimages\u003c/code\u003e folder inside this post directory.\u003c/li\u003e\n\u003cli\u003eDifferent media rendering like image, tweet, YouTube video, Vimeo video etc.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"image-sample\"\u003eImage Sample\u003c/h3\u003e\n\u003cimg src=\"/posts/category/sub-category/rich-content/images/forest.jpg\"\n    \n        alt=\"Forest\"\n    \n    \n    \n    \n    \n        class=\"center\"\n    \n\u003e\n\n\u003cdiv style=\"margin-top: rem;\"\u003e\u003c/div\u003e\n\u003ch3 id=\"tweet-sample\"\u003eTweet Sample\u003c/h3\u003e\n\u003cblockquote class=\"twitter-tweet\"\u003e\u003cp lang=\"en\" dir=\"ltr\"\u003eOwl bet you\u0026#39;ll lose this staring contest 🦉 \u003ca href=\"https://t.co/eJh4f2zncC\"\u003epic.twitter.com/eJh4f2zncC\u003c/a\u003e\u003c/p\u003e\u0026mdash; San Diego Zoo Wildlife Alliance (@sandiegozoo) \u003ca href=\"https://twitter.com/sandiegozoo/status/1453110110599868418?ref_src=twsrc%5Etfw\"\u003eOctober 26, 2021\u003c/a\u003e\u003c/blockquote\u003e\n\u003cscript async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"\u003e\u003c/script\u003e\n\n\n\u003cdiv style=\"margin-top: rem;\"\u003e\u003c/div\u003e\n\u003ch3 id=\"youtube-video-sample\"\u003eYouTube Video Sample\u003c/h3\u003e\n\n\n    \n    \u003cdiv style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"\u003e\n      \u003ciframe allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen=\"allowfullscreen\" loading=\"eager\" referrerpolicy=\"strict-origin-when-cross-origin\" src=\"https://www.youtube.com/embed/ZJthWmvUzzc?autoplay=0\u0026controls=1\u0026end=0\u0026loop=0\u0026mute=0\u0026start=0\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" title=\"YouTube video\"\n      \u003e\u003c/iframe\u003e\n    \u003c/div\u003e\n\n\u003cdiv style=\"margin-top: rem;\"\u003e\u003c/div\u003e\n\u003ch3 id=\"vimeo-video-sample\"\u003eVimeo Video Sample\u003c/h3\u003e\n\n\u003cdiv style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"\u003e\n  \u003ciframe src=\"https://player.vimeo.com/video/48912912\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" title=\"vimeo video\" webkitallowfullscreen mozallowfullscreen allowfullscreen\u003e\u003c/iframe\u003e\n\u003c/div\u003e","tags":["Markdown","Content Organization","Multi-lingual"],"title":"丰富的内容"},{"categories":["Basic"],"contents":"Greeting! This is an introduction post. This post tests the followings:\nHero image is in the same directory as the post. This post should be at top of the sidebar. Post author should be the same as specified in author.yaml file. ","date":"June 8, 2020","hero":"/posts/example/introduction/hero.svg","permalink":"https://online727.github.io/cn/posts/example/introduction/","summary":"\u003cp\u003eGreeting! This is an introduction post. This post tests the followings:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHero image is in the same directory as the post.\u003c/li\u003e\n\u003cli\u003eThis post should be at top of the sidebar.\u003c/li\u003e\n\u003cli\u003ePost author should be the same as specified in \u003ccode\u003eauthor.yaml\u003c/code\u003e file.\u003c/li\u003e\n\u003c/ul\u003e","tags":["Basic","Multi-lingual"],"title":"介绍"}]