[{"categories":null,"contents":" Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.Println(\u0026#34;Value is\u0026#34;, b) func getPointer () (myPointer *int) { a := 234 return \u0026amp;a a := new(int) *a = 234 Pointers point to a memory location of a variable. Go is fully garbage-collected.\nType Conversion i := 2 f := float64(i) u := uint(i) Slice slice := []int{2, 3, 4} slice := []byte(\u0026#34;Hello\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/notes/example/testnotes/simpletest/","summary":"Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.","tags":null,"title":"简单测试"},{"categories":null,"contents":"1. 线性回归 1.1 线性回归的基本元素 1.1.1 线性模型 线性回归，假设自变量 $\\bold{x}$ 和因变量 $y$ 之间为线性关系，其中可能包含噪声，但噪声是比较正常的，如噪声服从正态分布。\n给定一个样本 $\\bold{x}\\in\\mathbb{R}^{d}$，即具有 $d$ 个特征，将所有系数记为 $\\bold{w}\\in\\mathbb{R}^{d}$，线性回归的基本形式为： $$ \\hat{y} = \\bold{w}^{T}\\bold{x} + b $$\n矩阵形式下，$\\bold{X}\\in\\mathbb{R}^{n\\times d}$ 为所有样本的特征，此时线性回归表示为： $$ \\hat{\\bold{y}} = \\bold{Xw} + b $$\n给定训练数据集 $\\bold{X}$ 和对应标签 $\\bold{y}$，线性回归的目标就是找到一组权重向量 $\\bold{w}$ 和偏置 $b$，使得所有样本的预测误差尽可能小。\n1.1.2 损失函数 损失函数，用以度量上面提到的 “预测误差”，通常选择一个非负数作为损失，且该损失越小越好。回归问题中，最常用的损失函数为 平方误差，当样本 $i$ 的预测值为 $\\hat{y}^{(i)}$，相应真实标签为 $y^{(i)}$ 时，平方误差定义为： $$ l^{(i)}(\\bold{w}, b) = \\frac{1}{2}\\left(\\hat{y}^{(i)} - y^{(i)} \\right)^{2} $$\n$\\frac{1}{2}$ 是为了损失函数求导时常数系数为 1,不会有本质差别。\n那么，为了度量模型在整个训练集上的表现，就需要计算在整个训练集 $n$ 个样本上的损失均值 (等价于求和)： $$ L(\\bold{w}, b) = \\frac{1}{n}\\sum_{i=1}^{n}l^{(i)}(\\bold{w},b) = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{1}{2}\\left(\\bold{w}^{T}\\bold{x}^{(i)} + b - y^{(i)} \\right)^{2} $$\n此时，模型训练的目标就是寻找一组参数 $(\\bold{w}^{*},b^{*})$，以最小化所有训练样本上的总损失，即： $$ \\bold{w}^{*},b^{*} = \\argmin_{\\bold{w},b}L(\\bold{w},b) $$\n1.1.3 解析解 线性回归可以求出解析解，将偏置 $b$ 合并到权重 $\\bold{w}$ 中，最小二乘法，即可得到： $$ \\bold{w}^{*} = (\\bold{X}^{T}\\bold{X})^{-1}\\bold{X}^{T}\\bold{y} $$\n1.1.4 随机梯度下降 对于其他更复杂的模型，可能不存在解析解，那么就需要使用一些数值优化方法，以求得数值解。深度学习中常用 梯度下降法 (Gradient Decent)。梯度下降通过计算损失函数关于模型参数的导数 (此处也可称为梯度)，来更新参数。在实际中遍历整个数据集可能非常缓慢，所以我们通常每次随机抽取一小批样本计算，这种方法称为 小批量随机梯度下降 (minibatch stochastic gradient decent)。\n每次迭代，随机抽取一个小批量 $B$，计算该批次的损失均值关于参数的导数，乘以一个预先确定的正数 $\\eta$ (学习率)，并从当前参数中减去，以数学公式表示如下： $$ (\\bold{w}, b)\\leftarrow(\\bold{w}, b) - \\frac{\\eta}{|B|}\\sum_{i\\in B}\\partial_{\\bold{w}, b}l^{(i)}(\\bold{w}, b) $$\n总结：算法步骤如下：\n初始化模型参数，如随机初始化 从数据集抽取小批量样本且在负梯度方向上更新参数，并不断迭代这个步骤 对于平方损失函数，我们有： $$ \\begin{align*} \\bold{w}\u0026amp;\\leftarrow \\bold{w} - \\frac{\\eta}{|B|}\\sum_{i\\in B}\\partial_{\\bold{w}}l^{(i)}(\\bold{w}, b) = \\bold{w} - \\frac{\\eta}{|B|}\\sum_{i\\in B}\\bold{x}^{(i)}(\\bold{w}^{T}\\bold{x}^{(i)} + b - y^{(i)}) \\cr b\u0026amp;\\leftarrow b - \\frac{\\eta}{|B|}\\sum_{i\\in B}\\partial_{b}l^{(i)}(\\bold{w}, b) = b - \\frac{\\eta}{|B|}\\sum_{i\\in B}(\\bold{w}^{T}\\bold{x}^{(i)} + b - y^{(i)}) \\end{align*} $$\n批量大小 $B$ (batch size) 和学习率 $\\eta$ (learning rate) 通常是预先确定的，此类参数称为超参数 (hyperparameter)，调参 (hyperparameter tuning) 就是选择超参数的过程。这个选择过程通常是根据训练迭代的结果来调整的，训练迭代结果一般在独立的 验证数据集 (validation dataset) 上得到。\n我们的最终目标是：通过训练集的训练和验证集上参数的选择，找到一组具有比较良好泛化 (generalization) 能力的模型参数的估计值 $\\hat{\\bold{w}},\\hat{b}$，使其在没有见过的样本上也具有较小的损失。\n1.2 正态分布与平方损失 线性回归中假设观测中包含噪声，而该噪声服从正态分布，这也是为什么线性回归可以使用均方误差的原因。噪声正态分布如下式： $$ y = \\bold{w}^{T}\\bold{x}^{(i)} + b + \\epsilon, \\epsilon\\sim N(0, \\sigma^{2}) $$\n下面证明为什么可以使用均方损失。给定 $\\bold{x}$ 时 观测到 $y$ 的似然 (likelihood) 为： $$ P(y|\\bold{x}) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp\\left(-\\frac{1}{2\\sigma^{2}}(y - \\bold{w}^{T}\\bold{x}^{(i)} - b)^{2} \\right) $$\n利用极大似然估计，参数 $\\bold{w}, b$ 的最优值是使整个数据集的似然最大的值，即： $$ P(\\bold{y}|\\bold{X}) = \\prod_{i=1}^{n}p(y^{(i)}|\\bold{x}^{(i)}) $$\n极大似然估计法得到的估计量称为极大似然估计量，取对数，再取负，则可以将目标变为最小化负对数似然 $-\\log P(\\bold{y}|\\bold{X})$，即： $$ -\\log P(\\bold{y}|\\bold{X}) = \\sum_{i=1}^{n}\\frac{1}{2}\\log(2\\pi\\sigma^{2}) + \\frac{1}{2\\sigma^{2}}(y^{(i)} - \\bold{w}^{T}\\bold{x}^{(i)} - b)^{2} $$\n在正态噪声的假设下，再假设 $\\sigma$ 为常数，上式即与均方误差等价。\n2. 从零开始实现线性回归 生成数据集 def synthetic_data(w, b, num_examples): \u0026#34;\u0026#34;\u0026#34;生成 y = Xw + b + 噪声\u0026#34;\u0026#34;\u0026#34; X = torch.normal(0, 1, (num_examples, len(w))) y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) return X, y.reshape((-1, 1)) true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = synthetic_data(true_w, true_b, 1000) 读取数据集，随机取一个小批量 def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) # 样本随机读取，没有特定的顺序 random.shuffle(indices) for i in range(0, num_examples, batch_size): batch_indices = torch.tensor( indices[i: min(i + batch_size, num_examples)]) yield features[batch_indices], labels[batch_indices] 初始化模型参数，正态分布初始化 w = torch.normal(0, 0.01, size=(2,1), requires_grad=True) b = torch.zeros(1, requires_grad=True) 定义模型 def linreg(X, w, b): \u0026#34;\u0026#34;\u0026#34;线性回归模型\u0026#34;\u0026#34;\u0026#34; return torch.matmul(X, w) + b 定义损失函数 def squared_loss(y_hat, y): \u0026#34;\u0026#34;\u0026#34;均方损失\u0026#34;\u0026#34;\u0026#34; return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 定义优化算法 def sgd(params, lr, batch_size): \u0026#34;\u0026#34;\u0026#34;小批量随机梯度下降\u0026#34;\u0026#34;\u0026#34; with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size param.grad.zero_() 训练 lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) # X 和 y 的小批量损失 # 因为 l 形状是 (batch_size,1)，而不是一个标量。l 中的所有元素被加到一起， # 并以此计算关于 [w, b] 的梯度 l.sum().backward() sgd([w, b], lr, batch_size) # 使用参数的梯度更新参数 with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;) 3. 线性回归的简洁实现 生成数据集 import numpy as np import torch from torch.utils import data from d2l import torch as d2l true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = d2l.synthetic_data(true_w, true_b, 1000) 读取数据集 def load_array(data_arrays, batch_size, is_train=True): \u0026#34;\u0026#34;\u0026#34;构造一个 PyTorch 数据迭代器\u0026#34;\u0026#34;\u0026#34; dataset = data.TensorDataset(*data_arrays) return data.DataLoader(dataset, batch_size, shuffle=is_train) batch_size = 10 data_iter = load_array((features, labels), batch_size) 定义模型 net 是一个 Sequential 类的实例。 Sequential 类将多个层串联在一起。 当给定输入数据时，Sequential 实例将数据传入到第一层， 然后将第一层的输出作为第二层的输入，以此类推。 # nn 是神经网络的缩写 from torch import nn net = nn.Sequential(nn.Linear(2, 1)) 初始化模型参数 在使用 net 之前，需要初始化模型参数。深度学习框架通常有预定义的方法来初始化参数，在这里，我们指定每个权重参数应该从均值为 0、标准差为 0.01 的正态分布中随机采样，偏置参数将初始化为零。 通过 net[0] 选择网络中的第一个图层，然后使用 weight.data 和 bias.data 方法访问参数，使用替换方法 normal_ 和 fill_ 来重写参数值。 net[0].weight.data.normal_(0, 0.01) net[0].bias.data.fill_(0) 定义损失函数 计算均方误差使用的是 MSELoss 类，也称为平方 $L_{2}$ 范数。默认情况下，它返回所有样本损失的平均值。 loss = nn.MSELoss() 定义优化算法 PyTorch 在 optim 模块中实现了该算法的许多变种。实例化一个 SGD 实例，指定优化的参数 (可通过 net.parameters() 从我们的模型中获得) 以及优化算法所需的超参数。小批量随机梯度下降只需要设置 lr 值，这里设置为 0.03。 trainer = torch.optim.SGD(net.parameters(), lr=0.03) 训练 num_epochs = 3 for epoch in range(num_epochs): for X, y in data_iter: l = loss(net(X) ,y) trainer.zero_grad() l.backward() trainer.step() l = loss(net(features), labels)线性模型 print(f\u0026#39;epoch {epoch + 1}, loss {l:f}\u0026#39;) 4. Softmax 回归 前述内容是应用于回归预测的线性模型，除此之外，它也可以用于分类问题。\n4.1 分类问题 在样本特征方面，与回归类似，每个样本有一个特征向量。而在预测标签方面，如预测猫、狗、鸡，一个直接的想法是选择 ${1,2,3}$，但这会为类别赋予“顺序”信息，在类别间有一定自然顺序时，这样做是可行的，如 ${婴儿，儿童，青年，老年}$，但该类问题亦可以转化为回归问题。因此，在预测标签方面，一般使用 独热编码 (one-hot encoding)。独热编码是一个具有与类别数相同个数分量的向量，类别对应的分量设为 1，其余为 0。如猫、狗、鸡可以设置为 ${(1,0,0),(0,1,0),(0,0,1)}$。\n4.2 网络架构 为了估计所有可能类别的条件概率，就需要一个多输出的模型，每个类别对应一个输出，即设置与类别个数相同的仿射函数。假设如上的例子中有 4 个特征，那么我们便需要 3 个 4 元回归方程，共 12 个参数、4 各偏置。如下我们为每个输入计算 3 个未规范化的预测 (logit) $o_{1},o_{2},o_{3}$： $$ \\begin{align*} o_{1} \u0026amp;= x_{1}w_{11} + x_{2}w_{12} + x_{3}w_{13} + x_{4}w_{14} + b_{1} \\cr o_{2} \u0026amp;= x_{1}w_{21} + x_{2}w_{22} + x_{3}w_{23} + x_{4}w_{24} + b_{2} \\cr o_{3} \u0026amp;= x_{1}w_{31} + x_{2}w_{32} + x_{3}w_{33} + x_{4}w_{34} + b_{3} \\end{align*} $$\n仍将模型表达为矩阵形式，则有 $\\bold{o=Wx+b}, W\\in\\mathbb{R}^{3\\times4}, x\\in\\mathbb{R}^{4}, b\\in\\mathbb{R}^{3}$。\n只使用一个神经层进行 softmax 回归时，输出层同时也是全连接层，其参数开销为 $O(dq)$，$d$ 是输入维度，$q$ 是输出维度，在实践中可能非常大，但有一定的方式可以把这个开销降低至 $O(dq/n)$，$n$ 为超参数，可以灵活设置，以在参数节省和模型有效性间合理权衡。\n4.3 softmax 运算 上述网络的输出是未经规范化的预测：我们没有限制它们的和为 1，也没有限制它们的值不能为负，这违背了概率公理，因此，若要将输出视为概率，我们需要保证输出非负且和为 1，且需要一个目标函数，以激励模型精准地估计概率，该属性称之为 校准 (calibration)。\nsoftmax 函数正是我们所需要的，其计算公式如下： $$ \\hat{\\bold{y}} = softmax(\\bold{o}), \\hat{y}_{j}=\\frac{\\exp (o_j)}{\\sum_k \\exp (o_k)} $$\n该函数不会改变原有的大小次序，且可导，我们认可通过下式选择最有可能的类别： $$ \\argmax_{j}\\hat{y}_{j} = \\argmax_jo_j $$\n4.4 批量样本的向量化 将上述内容结合批量，输入数据为 $\\bold{X}\\in\\mathbb{R}^{n\\times d}$，权重为 $\\bold{W}\\in\\mathbb{R}^{d\\times q}$，偏置为 $\\bold{b}\\in\\mathbb{1\\times q}$，则 softmax 可以写为： $$ \\begin{align*} \\bold{O}\u0026amp;=\\bold{XW+b} \\cr \\hat{\\bold{Y}} \u0026amp;= softmax(\\bold{O}) \\end{align*} $$\n其中，softmax 函数按行运算。\n4.5 损失函数 softmax 函数的输出给出了一个向量 $\\hat{\\bold{y}}$，可以理解为任意给定输入 $\\bold{x}$ 时每个类别的条件概率，设整个数据集 ${\\bold{X,Y}}$ 有 $n$ 个样本，索引 $i$ 的特征向量和独热标签向量分别为：$\\bold{x}^{(i)},\\bold{y}^{(i)}$，比较估计值和真实值即有： $$ P(\\bold{Y}|\\bold{X})=\\prod_{i=1}^{n}P(\\bold{y}^{(i)}|\\bold{x}^{(i)}) $$\n进行极大似然估计，最大化 $P(\\bold{Y}|\\bold{X})$，即最小化负对数似然： $$ -\\log P(\\bold{Y}|\\bold{X}) = \\sum_{i=1}^{n}-\\log P(\\bold{y}^{(i)}|\\bold{x}^{(i)}) = \\sum_{i=1^{n}}l(\\bold{y}^{(i)}, \\hat{\\bold{y}}^{(i)}) $$\n其中，对于任意标签 $\\bold{y}$ 和模型预测 $\\hat{\\bold{y}}^{(i)}$，损失函数为： $$ l(\\bold{y}^{(i)}, \\hat{\\bold{y}}^{(i)})=-\\sum_{j=1}^{q}y_{i}\\log\\hat{y}_{j} $$\n上式通常称为 交叉熵损失 (cross-entropy loss)。注意，$\\bold{y}$ 是一个长度为 $q$ 的独热编码向量，即只有一个分量为 1，则该式仅有一项，且由于概率值不大于 1，因此取对数后不大于 0，则该损失函数永远是一个非负值，预测的概率越准确，该值越接近于 0。\n将 $\\hat{y}$ 的 softmax 计算代入上式，则有： $$ \\begin{align*} l(\\bold{y}^{(i)}, \\hat{\\bold{y}}^{(i)}) \u0026amp;= -\\sum_{j=1}^{q}y_j\\log\\frac{\\exp (o_j)}{\\sum_{k=1}^{q}\\exp (o_k)} \\cr \u0026amp;= \\sum_{j=1}^{q}y_{j}\\log\\sum_{k=1}^{q}\\exp(o_k) - \\sum_{j=1}^{q}y_jo_j \\cr \u0026amp;= \\log\\sum_{k=1}^{q}\\exp(o_k) - \\sum_{j=1}^{q}y_jo_j \\end{align*} $$\n对任意为规范化的预测 $o_j$ 求导可得： $$ \\partial_{o_{j}}l(\\bold{y}^{(i)}, \\hat{\\bold{y}}^{(i)})=\\frac{\\exp(o_j)}{\\sum_{k=1}^{q}\\exp (o_k)} - y_j = softmax(\\bold{o})_j - y_j $$\n即：导数是我们 softmax 函数分配的概率与真实独热标签表示的概率之间的差。\n最后，我们的模型对任意样本的特征输出每个类别的概率，一般取其中预测概率最高的类别作为输出类别。\n5. Fashion-MNIST 数据集 Fashion-MNIST 数据集包含 10 个类别的图像，高度和宽度为 28 像素，灰度图像，通道数为 1。训练集和测试集分别包括 60000 和 10000 张图像。首先读取数据集，并定义绘图和标签转换函数。\n%matplotlib inline import torch import torchvision from torch.utils import data from torchvision import transforms from d2l import torch as d2l d2l.use_svg_display() # 通过 ToTensor 实例将图像数据从 PIL 类型变换成 32 位浮点数格式， # 并除以 255 使得所有像素的数值均在 0～1 之间 trans = transforms.ToTensor() mnist_train = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True) mnist_test = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True) def get_fashion_mnist_labels(labels): \u0026#34;\u0026#34;\u0026#34;返回 Fashion-MNIST 数据集的文本标签\u0026#34;\u0026#34;\u0026#34; text_labels = [\u0026#39;t-shirt\u0026#39;, \u0026#39;trouser\u0026#39;, \u0026#39;pullover\u0026#39;, \u0026#39;dress\u0026#39;, \u0026#39;coat\u0026#39;, \u0026#39;sandal\u0026#39;, \u0026#39;shirt\u0026#39;, \u0026#39;sneaker\u0026#39;, \u0026#39;bag\u0026#39;, \u0026#39;ankle boot\u0026#39;] return [text_labels[int(i)] for i in labels] def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5): \u0026#34;\u0026#34;\u0026#34;绘制图像列表\u0026#34;\u0026#34;\u0026#34; figsize = (num_cols * scale, num_rows * scale) _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize) axes = axes.flatten() for i, (ax, img) in enumerate(zip(axes, imgs)): if torch.is_tensor(img): # 图片张量 ax.imshow(img.numpy()) else: # PIL 图片 ax.imshow(img) ax.axes.get_xaxis().set_visible(False) ax.axes.get_yaxis().set_visible(False) if titles: ax.set_title(titles[i]) return axes def get_dataloader_workers(): \u0026#34;\u0026#34;\u0026#34;使用 4 个进程来读取数据\u0026#34;\u0026#34;\u0026#34; return 4 def load_data_fashion_mnist(batch_size, resize=None): \u0026#34;\u0026#34;\u0026#34;下载 Fashion-MNIST 数据集，然后将其加载到内存中\u0026#34;\u0026#34;\u0026#34; # 通过 ToTensor 实例将图像数据从 PIL 类型变换成 32 位浮点数格式 trans = [transforms.ToTensor()] # 使用 resize 将图像调整到另一种形状 if resize: trans.insert(0, transforms.Resize(resize)) trans = transforms.Compose(trans) # 下载数据集 mnist_train = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True) mnist_test = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True) # 返回内置数据迭代器 return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()), data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers())) train_iter, test_iter = load_data_fashion_mnist(32, resize=64) for X, y in train_iter: print(X.shape, X.dtype, y.shape, y.dtype) break 6. softmax 回归从零实现 首先，加载数据并初始化模型参数：\nimport torch from IPython import display from d2l import torch as d2l batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) num_inputs = 784 # 28*28 的图像视为一维向量 num_outputs = 10 # 对应 10 个类别 W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True) # 784*10 b = torch.zeros(num_outputs, requires_grad=True) # 1*10 定义模型、softmax 函数、损失函数、分类精度、评估函数：\ndef softmax(X): X_exp = torch.exp(X) partition = X_exp.sum(1, keepdim=True) return X_exp / partition def net(X): return softmax(torch.matmul(X.reshape(-1, W.shape[0]), W) + b) def cross_entropy(y_hat, y): return - torch.log(y_hat[range(len(y_hat)), y]) def accuracy(y_hat, y): \u0026#34;\u0026#34;\u0026#34;计算预测正确的数量\u0026#34;\u0026#34;\u0026#34; if (len(y_hat.shape) \u0026gt; 1) and (y_hat.shape[1] \u0026gt; 1): y_hat = y_hat.argmax(axis=1) cmp = y_hat.type(y.dtype) == y return float(cmp.type(y.dtype).sum()) def evaluate_accuracy(net, data_iter): \u0026#34;\u0026#34;\u0026#34;计算在指定数据集上模型的精度\u0026#34;\u0026#34;\u0026#34; if isinstance(net, torch.nn.Module): net.eval() # 将模型设置为评估模式 metric = d2l.Accumulator(2) # 正确预测数、预测总数 with torch.no_grad(): for X, y in data_iter: metric.add(accuracy(net(X), y), y.numel()) return metric[0] / metric[1] 定义训练、预测过程：\ndef train_epoch_ch3(net, train_iter, loss, updater): \u0026#34;\u0026#34;\u0026#34;训练模型一个迭代周期（定义见第 3 章）\u0026#34;\u0026#34;\u0026#34; # 将模型设置为训练模式 if isinstance(net, torch.nn.Module): net.train() # 训练损失总和、训练准确度总和、样本数 metric = Accumulator(3) for X, y in train_iter: # 计算梯度并更新参数 y_hat = net(X) l = loss(y_hat, y) if isinstance(updater, torch.optim.Optimizer): # 使用 PyTorch 内置的优化器和损失函数 updater.zero_grad() l.mean().backward() updater.step() else: # 使用定制的优化器和损失函数 l.sum().backward() updater(X.shape[0]) metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) # 返回训练损失和训练精度 return metric[0] / metric[2], metric[1] / metric[2] def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): \u0026#34;\u0026#34;\u0026#34;训练模型（定义见第 3 章）\u0026#34;\u0026#34;\u0026#34; animator = d2l.Animator(xlabel=\u0026#39;epoch\u0026#39;, xlim=[1, num_epochs], ylim=[0.3, 0.9], legend=[\u0026#39;train loss\u0026#39;, \u0026#39;train acc\u0026#39;, \u0026#39;test acc\u0026#39;]) for epoch in range(num_epochs): train_metrics = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) animator.add(epoch + 1, train_metrics + (test_acc,)) train_loss, train_acc = train_metrics assert train_loss \u0026lt; 0.5, train_loss assert train_acc \u0026lt;= 1 and train_acc \u0026gt; 0.7, train_acc assert test_acc \u0026lt;= 1 and test_acc \u0026gt; 0.7, test_acc lr = 0.1 def updater(batch_size): return d2l.sgd([W, b], lr, batch_size) num_epochs = 10 train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater) def predict_ch3(net, test_iter, n=6): \u0026#34;\u0026#34;\u0026#34;预测标签（定义见第 3 章）\u0026#34;\u0026#34;\u0026#34; for X, y in test_iter: break trues = d2l.get_fashion_mnist_labels(y) preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1)) titles = [true +\u0026#39;\\n\u0026#39; + pred for true, pred in zip(trues, preds)] d2l.show_images( X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n]) predict_ch3(net, test_iter) 7. softmax 回归的简洁实现 import torch from torch import nn from d2l import torch as d2l # 加载数据 batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) # 定义网络 # PyTorch 不会隐式地调整输入的形状。因此，我们在线性层前定义了展平层（flatten），来调整网络输入的形状 net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights) # 损失函数 # PyTorch 为交叉熵损失函数传递未规范化的预测，在函数中再计算 softmax 及其对数 loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) # 优化器 trainer = torch.optim.SGD(net.parameters(), lr=0.1) # 训练 num_epochs = 10 d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) 7.1 重新审视 softmax 的实现 softmax 函数中需要取 $\\exp$，在遇到较大的 $o_k$ 时，可能会导致数值 上溢，最终结果可能出现 0、inf 或 nan 值。\n我们可以通过为所有 $o_k$ 减去 $\\max(o_k)$ 来解决上溢问题，因为： $$ \\begin{align*} \\hat{y}_j \u0026amp;= \\frac{\\exp(o_j-\\max(o_k))\\exp(\\max(o_k))}{\\sum_k\\exp(o_k-\\max(o_k))\\exp(\\max(o_k))} \\cr \u0026amp;= \\frac{\\exp(o_j-\\max(o_k))}{\\sum_k\\exp(o_k-\\max(o_k))} \\end{align*} $$\n但在上述减法和规范化步骤后，可能有一些 $o_j-\\max(o_k)$ 出现较大负值，取指数后的值非常接近 0，即 下溢，则最后取对数时得到 -inf 值。\n但幸运的是，尽管我们要计算指数函数，但我们最终在计算交叉熵损失时会取它们的对数。 通过将 softmax 和交叉熵结合在一起，可以避免反向传播过程中可能会困扰我们的数值稳定性问题。 如下面的等式所示，我们避免计算 $\\exp(o_j-\\max(o_k))$，直接使用 $o_j-\\max(o_k)$： $$ \\begin{align*} \\log(\\hat{y}_j) \u0026amp;= \\log\\left(\\frac{\\exp(o_j-\\max(o_k))}{\\sum_k\\exp(o_k-\\max(o_k))}\\right) \\cr \u0026amp;= \\log(\\exp(o_j-\\max(o_k))) - \\log\\left(\\sum_k\\exp(o_k-\\max(o_k))\\right) \\cr \u0026amp;= o_j-\\max(o_k) - \\log\\left(\\sum_k\\exp(o_k-\\max(o_k))\\right) \\end{align*} $$\nPyTorch 没有将 softmax 概率传递到损失函数中， 而是在交叉熵损失函数中传递未规范化的预测，在函数中再计算 softmax 及其对数， 这是一种类似 “LogSumExp 技巧” 的聪明方式。\n","date":"July 28, 2024","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/posts/dltorch/ch3/","summary":"1. 线性回归 1.1 线性回归的基本元素 1.1.1 线性模型 线性回归，假设自变量 $\\bold{x}$ 和因变量 $y$ 之间为线性关系，其中可能包含噪声，但噪声是比较正常的，如噪声服从正态分布。\n给定一个样本 $\\bold{x}\\in\\mathbb{R}^{d}$，即具有 $d$ 个特征，将所有系数记为 $\\bold{w}\\in\\mathbb{R}^{d}$，线性回归的基本形式为： $$ \\hat{y} = \\bold{w}^{T}\\bold{x} + b $$\n矩阵形式下，$\\bold{X}\\in\\mathbb{R}^{n\\times d}$ 为所有样本的特征，此时线性回归表示为： $$ \\hat{\\bold{y}} = \\bold{Xw} + b $$\n给定训练数据集 $\\bold{X}$ 和对应标签 $\\bold{y}$，线性回归的目标就是找到一组权重向量 $\\bold{w}$ 和偏置 $b$，使得所有样本的预测误差尽可能小。\n1.1.2 损失函数 损失函数，用以度量上面提到的 “预测误差”，通常选择一个非负数作为损失，且该损失越小越好。回归问题中，最常用的损失函数为 平方误差，当样本 $i$ 的预测值为 $\\hat{y}^{(i)}$，相应真实标签为 $y^{(i)}$ 时，平方误差定义为： $$ l^{(i)}(\\bold{w}, b) = \\frac{1}{2}\\left(\\hat{y}^{(i)} - y^{(i)} \\right)^{2} $$\n$\\frac{1}{2}$ 是为了损失函数求导时常数系数为 1,不会有本质差别。\n那么，为了度量模型在整个训练集上的表现，就需要计算在整个训练集 $n$ 个样本上的损失均值 (等价于求和)： $$ L(\\bold{w}, b) = \\frac{1}{n}\\sum_{i=1}^{n}l^{(i)}(\\bold{w},b) = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{1}{2}\\left(\\bold{w}^{T}\\bold{x}^{(i)} + b - y^{(i)} \\right)^{2} $$","tags":["深度学习","Pytorch","LinearRegression","SoftMax"],"title":"第三章 线性神经网络"},{"categories":null,"contents":"接下来一段时间，我想自学深度学习，使用的教材为 动手学深度学习 (Pytorch 版)，该书有线上网址，且提供配套代码和相关 Python 包，详情可参见 动手学深度学习。\n第一章内容，介绍了深度学习的相关背景和应用场景，以及深度学习领域常见的术语和名词，有一定机器学习经验的人或许已比较熟悉，故不再赘述，我们直接从第二章开始。\n1. Tensor 操作和数据预处理 深度学习中的数据以张量 (tensor) 形式存储，支持 GPU 计算和 autograd 自动微分。\n张量的创建、变形、运算 (按元素 / 矩阵)、广播机制、索引、切片等均与 numpy.ndarray 类似。\n节省内存： Y = X + Y 不是原地操作，即：id(Y = X + Y) != id(Y)，会分配新的内存。 使用 Y[:] = X + Y 或 Y += X 进行原地操作以避免不必要的内存分配。 Tensor 可以与其他 Python 对象互相转换，如 tensor.numpy()。大小为 1 的张量可以转化为 Python 标量，使用 tensor.item() 或 float(tensor) 等。\n数据需要经过预处理，如填充 nan，标准化等，可以借用其他 Python 包处理后再转化为 tensor。\n2. 线性代数 标量，以小写字母 $x,y,z$ 等表示。 向量，以粗体小写字母 $\\bold{x,y,z}$ 表示，向量的维度 (形状) 代表元素个数 (向量长度)，可以使用 len(x), x.shape 获取。以列向量为默认的向量方向，例如： $$ \\begin{equation*} x = \\begin{bmatrix*} x_{1} \\cr x_{2} \\cr \\vdots \\cr x_{n} \\end{bmatrix*} \\end{equation*} $$ 矩阵，以粗体大写字母 $\\bold{X,Y,Z}$ 表示，是具有两个轴的张量。 张量 (此处指代数对象)，矩阵的拓展，一种具有更多轴的数据结构，使用特殊字体的大写字母 $X, Y, Z$ 表示。 张量的计算，与 numpy.ndarray 相同，普通的加减乘除、求和、平均、向量点积、矩阵 hadamard 积、矩阵-向量积、矩阵乘法、范数等。\n3. 微积分 3.1 导数和微分 设 $y=f(x)$，其导数被定义为： $$ f^{\u0026rsquo;}(x) = \\lim_{h\\rightarrow 0}\\frac{f(x+h) - f(x)}{h} $$\n以下符号等价： $$ f^{\u0026rsquo;}(x)=y^{\u0026rsquo;}=\\frac{dy}{dx}=\\frac{df}{dx}=\\frac{d}{dx}f(x)=Df(x)=D_{x}f(x) $$\n自行回顾求导法则。\n3.2 偏导数 将微分的思想拓展至多元函数上，设 $y=f(x_{1},\\cdots,x_{n})$ 是一个 $n$ 元函数，其关于第 $i$ 个变量 $x_{i}$ 的偏导数为： $$ \\frac{\\partial y}{\\partial x_{i}} = \\lim_{h\\rightarrow 0}\\frac{f(x_{1},\\cdots,x_{i-1},x_{i}+h,x_{i+1},\\cdots,x_{n}) - f(x_{1},\\cdots,x_{i},\\cdot,x_{n})}{h} $$\n以下表达等价： $$ \\frac{\\partial y}{\\partial x_{i}} = \\frac{\\partial f}{\\partial x_{i}} = f_{x_{i}} = f_{i} = D_{i}f = D_{x_{i}}f $$\n3.3 梯度 函数的梯度（gradient）向量，即其对所有变量的偏导数。设函数 $f: \\mathbb{R}^n \\to \\mathbb{R}$ 的输入是一个 $n$ 维向量 $\\mathbf{x} = [x_1, x_2, \\ldots, x_n]$，并且输出是一个标量。函数 $f(\\mathbf{x})$ 相对于 $\\mathbf{x}$ 的梯度是一个包含 $n$ 个偏导数的向量： $$ \\nabla_{\\mathbf{x}} f(\\mathbf{x}) = \\begin{bmatrix} \\frac{\\partial f(\\mathbf{x})}{\\partial x_1} \u0026amp; \\frac{\\partial f(\\mathbf{x})}{\\partial x_2} \u0026amp; \\cdots \u0026amp; \\frac{\\partial f(\\mathbf{x})}{\\partial x_n} \\end{bmatrix}^\\top, $$\n假设 $\\mathbf{x}$ 为 $n$ 维向量，在微分多元函数时经常使用以下规则：\n对于所有 $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$，都有 $\\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} = \\mathbf{A}^\\top$ 对于所有 $\\mathbf{A} \\in \\mathbb{R}^{n \\times m}$，都有 $\\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{A} = \\mathbf{A}$ 对于所有 $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$，都有 $\\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{A} \\mathbf{x} = (\\mathbf{A} + \\mathbf{A}^\\top) \\mathbf{x}$ $\\nabla_{\\mathbf{x}} |\\mathbf{x}|^2 = \\nabla_{\\mathbf{x}} \\mathbf{x}^\\top \\mathbf{x} = 2 \\mathbf{x}$ 同样，对于任意矩阵 $\\mathbf{X}$，都有 $\\nabla_{\\mathbf{X}} |\\mathbf{X}|_F^2 = 2 \\mathbf{X}$。\n3.4 链式法则 考虑单变量函数 $y = f(u)$ 和 $u = g(x)$， 假设都是可微的，根据链式法则： $$ \\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx} $$\n当函数具有任意数量的变量时，假设可微分函数 $y$ 有变量 $u_1, u_2, \\cdots, u_m$，其中每个可微分函数 $u_i$ 都有变量 $x_1, x_2, \\cdots, x_n$。注意，$y$ 是 $x_1, x_2, \\cdots, x_n$ 的函数。对于任意 $i = 1, 2, \\cdots, n$，链式法则给出：\n$$ \\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial u_1} \\frac{\\partial u_1}{\\partial x_i} + \\frac{\\partial y}{\\partial u_2} \\frac{\\partial u_2}{\\partial x_i} + \\cdots + \\frac{\\partial y}{\\partial u_m} \\frac{\\partial u_m}{\\partial x_i}. $$\n4. 自动微分 Pytorch 使用自动微分 (automatic differentiation) 来加快求导。 实际中，根据设计好的模型，系统会构建一个计算图 (computational graph)，以跟踪计算是哪些数据通过哪些操作组合起来产生输出，并使用自动微分进行反向传播梯度。 这里，反向传播 (backpropagate) 意味着跟踪整个计算图，填充关于每个参数的偏导数。\n当 $y$ 是标量时，可以通过链式法则反向求导输入参数的梯度，该梯度是一个与输入向量 $\\bold{x}$ 形状相同的向量。\n当 $y$ 不是标量时，向量 $\\bold{y}$ 关于 $\\bold{x}$ 的导数是一个矩阵，更高阶情况下是一个高阶张量。但当调用向量的反向传播计算时，通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里、的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。如：\nx = torch.arange(4.0) y = x * x y.sum().backward() # y.backward(torch.ones(len(x))) 如果想将某些计算移到记录的计算图之外，例如，假设 $y$ 是作为 $x$ 的函数计算的，而 $z$ 则是作为 $y$ 和 $x$ 的函数计算的。比如，我们想计算 $z$ 关于 $x$ 的梯度，但由于某种原因，希望将 $y$ 视为一个常数，并且只考虑到 $x$ 在 $y$ 被计算后发挥的作用。\n此时，可以使用 detach() 分离 $y$ 来返回一个新变量 $u$，该变量与 $y$ 具有相同的值，但丢弃计算图中如何计算 $y$ 的任何信息。换句话说，梯度不会向后流经 $u$ 到 $x$。因此，下面的反向传播函数计算 $z=u*x$ 关于 $x$ 的偏导数，$u$ 为常数。\nx.grad.zero_() y = x * x u = y.detach() z = u * x z.sum().backward() 5. 概率 单个随机变量：概率分布 多个随机变量 联合概率 (联合分布) 条件概率 (条件分布) 贝叶斯定理 边际化 (边际概率、边际分布 \u0026ndash; 全概率公式) $$P(B)=\\sum_{A}P(A,B)$$ 独立性 期望和方差 ","date":"July 27, 2024","hero":"/images/default-hero.jpg","permalink":"https://online727.github.io/cn/posts/dltorch/ch2/","summary":"接下来一段时间，我想自学深度学习，使用的教材为 动手学深度学习 (Pytorch 版)，该书有线上网址，且提供配套代码和相关 Python 包，详情可参见 动手学深度学习。\n第一章内容，介绍了深度学习的相关背景和应用场景，以及深度学习领域常见的术语和名词，有一定机器学习经验的人或许已比较熟悉，故不再赘述，我们直接从第二章开始。\n1. Tensor 操作和数据预处理 深度学习中的数据以张量 (tensor) 形式存储，支持 GPU 计算和 autograd 自动微分。\n张量的创建、变形、运算 (按元素 / 矩阵)、广播机制、索引、切片等均与 numpy.ndarray 类似。\n节省内存： Y = X + Y 不是原地操作，即：id(Y = X + Y) != id(Y)，会分配新的内存。 使用 Y[:] = X + Y 或 Y += X 进行原地操作以避免不必要的内存分配。 Tensor 可以与其他 Python 对象互相转换，如 tensor.numpy()。大小为 1 的张量可以转化为 Python 标量，使用 tensor.item() 或 float(tensor) 等。\n数据需要经过预处理，如填充 nan，标准化等，可以借用其他 Python 包处理后再转化为 tensor。\n2. 线性代数 标量，以小写字母 $x,y,z$ 等表示。 向量，以粗体小写字母 $\\bold{x,y,z}$ 表示，向量的维度 (形状) 代表元素个数 (向量长度)，可以使用 len(x), x.","tags":["深度学习","Pytorch"],"title":"第二章 预备知识"},{"categories":null,"contents":"1. 摘要 投资组合的业绩归因可以分为 收益归因 和 风险归因 两个部分，而归因又可以基于净值或持仓进行。本文主要基于 持仓数据 对组合的业绩归因进行探讨。\n在组合收益归因方面，主要有以下部分：\n基于 Brinson 模型 经典版 BHB (Brinson, Hood and Beebower) 模型：将组合超额收益分解为配置收益、选股收益和交互收益 3 部分。 改进版 BF (Brinson and Fachler) 模型：引入行业超额收益，将组合超额收益分解为配置效应和选股效应两个部分。 基于多因子模型 基于行业的多因子收益归因：与自下而上的 Brinson 模型完全一致。 基于行业和风格的多因子收益归因：同时对行业和风格上的配置进行分析。 在组合风险归因方面，主要基于多因子模型：\n单一波动分解法：单独考虑每个因子，计算简单，但忽略因子之间的协同影响，且不具可加性。 边际风险分解法：将组合风险分解为因子暴露度与因子边际风险贡献的乘积，然而偏导数的概念相对模糊，指导意义不强。 三要素分解法：将风险分解为因子暴露 ($x$)、因子波动 ($\\sigma$) 和因子-组合相关系数 ($\\rho$)，对风险的分解更为透彻，更有利于投资经理对风险进行控制。 2. 基于 Brinson 模型的组合收益归因 2.1 经典 BHB 模型 BHB 模型将投资组合的超额收益率分解为 配置收益、选股收益和交互收益 三个部分，其基本框架如下图所示，其中红色渲染部分表示投资组合的超额收益。\n从行业配置的角度而言，假设 $w_{i}^{P}, w_{i}^{B}$ 分别表示投资组合和基准组合中行业 $i$ 的权重，$r_{i}^{P}, r_{i}^{B}$ 分别表示投资组合和基准组合中行业 $i$ 的收益率，那么投资组合的收益率 $R^{P}$ 和基准组合的收益率 $R^{B}$ 就可以表示为： $$ \\begin{align*} R^{P}\u0026amp;=\\sum_{i=1}^{I}w_{i}^{P}r_{i}^{P}, where\\sum_{i=1}^{I}w_{i}^{P}=1 \\cr R^{B}\u0026amp;=\\sum_{i=1}^{I}w_{i}^{B}r_{i}^{B}, where\\sum_{i=1}^{I}w_{i}^{B}=1 \\end{align*} $$\n其中，$I$ 表示行业个数。此时，投资组合超额收益 $R^{A}$ 即可表示为： $$ R^{A}=R^{P}-R^{B}=\\sum_{i=1}^{I}w_{i}^{P}r_{i}^{P} - \\sum_{i=1}^{I}w_{i}^{B}r_{i}^{B} $$\nBHB 模型将组合超额收益拆解为 配置收益 (Allocation Return, AR)、选股收益 (Selection Return, SR) 和 交互收益 (Interaction Return, IR) 三部分，即： $$ \\begin{align*} R^{A} \u0026amp;= AR+SR+IR \\cr AR \u0026amp;= \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})r_{i}^{B} \\cr SR \u0026amp;= \\sum_{i=1}^{I}w_{i}^{B}(r_{i}^{P} - r_{i}^{B}) \\cr IR \u0026amp;= R^{A} - AR - SR = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{P} - r_{i}^{B}) \\end{align*} $$\n配置收益 (AR) 等于投资组合在每个行业上的超额权重与基准行业收益率的乘积 (AR = 超额权重 × 基准行业收益率)，表示在行业内部不进行任何选股操作，持有与基准组合完全相同的行业，并通过超配收益为正、低配收益为负的行业所能够获取的超额收益。 选择收益 (SR) 等于基准权重与投资组合在行业上超额收益率的乘积 (SR = 基准权重 × 行业超额收益) ，表示在组合中保持每个行业权重与基准指数行业权重完全一致，通过行业内部的选股操作所能够获取的超额收益。 交互收益 (IR) 等于超额权重与超额收益的乘积 (IR = 超额权重 × 超额收益)，表示由配置和选股共同产生的超额收益。 本文的所有示例都是按照行业进行划分的，但 Brinson 模型的应用远不止于此。对于大类资产配置的投资者而言，他可以将收益拆解到股票、债券、现金、基金和衍生品等不同类别的大类资产配置和选择带来的收益，对于债券投资者而言，他可以将超额收益拆解到企业债、信用债、利率债、国债等不同债券类别的配置和选择带来的收益。\nBHB 模型存在的不足：\n配置效应 $AR = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})r_{i}^{B}$ 中，BHB 模型 认为超配行业绝对收益为正的行业即可获得配置效应，但若某些行业只是具有正收益，但却未能胜过基准组合，即：$0 \u0026lt; r_{i}^{B} \u0026lt; R^{B}$，那么超配此类行业显然不是完全成功的。 选择效应 $SR = \\sum_{i=1}^{I}w_{i}^{B}(r_{i}^{P} - r_{i}^{B})$ 中，当投资组合中某行业相对基准行业存在超额收益，但投资组合对该行业的权重配置低于基准权重配置，即：$w_{i}^{P} \u0026lt; w_{i}^{B}$，若仍按基准权重来计算选择效应，结果会存在一定高估。 交互效应 $IR = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{P} - r_{i}^{B})$ 的概念相对模糊，配置效应是对绝对收益为正的行业的超配、对绝对收益为负的行业的低配带来的收益，选股效应是对超额收益为正的个股的超配、对超额收益为负的个股低配带来的收益，但交互项收益部分很难从操作层面去解释，为组合的管理带来了难题。 2.2 改进版 BF 模型 BF 模型是 BHB 模型的改进版，增加了基准收益 $R^{B}$ 对配置收益的影响，基本框架如下图所示，其中仍以红色渲染部分表示投资组合的超额收益。\nBF 模型在配置效应部分的计算引入了基准收益 $R^{B}$，新的配置效应可以表示为： $$ AR_{BF}=\\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{B} - R^{B}) $$\n由于资产组合权重 $w_{i}^{P}$ 和基准组合权重 $w_{i}^{B}$ 加总均为 1，而 $R^{B}$ 是一个常数，因此： $$ \\begin{gather*} \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})R^{B} = 0 \\cr AR_{BHB} = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})r_{i}^{B} = \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{B} - R^{B}) = AR_{BF} \\end{gather*} $$\n也就是说，相较于 BHB 模型而言，BF 模型中对于基准收益的引入并不会改变其配置效应的大小，二者是完全等同的，但在直观解释上 BF 模型却与投资者的实际操作更为贴合，它认为：只有超配那些相较基准指数具有正向超额收益的行业、低配那些相较基准指数具有负向超额收益的行业，才能算是成功的行业配置策略。\nBF 模型还将 BHB 模型中的选择效应和交互效应进行了合并，形成新的选股效应： $$ \\begin{align*} SR_{BF} \u0026amp;= SR_{BHB} + IR_{BHB} \\cr \u0026amp;= \\sum_{i=1}^{I}w_{i}^{B}(r_{i}^{P} - r_{i}^{B}) + \\sum_{i=1}^{I}(w_{i}^{P} - w_{i}^{B})(r_{i}^{P} - r_{i}^{B}) \\cr \u0026amp;= \\sum_{i=1}^{I}w_{i}^{P}(r_{i}^{P} - r_{i}^{B}) \\end{align*} $$\n最后，BF 模型就将投资组合的超额收益 $R^{A}$ 分解到了对行业的配置效应 $AR$ 和行业内部的选股效应 $SR$ 两个部分： $$ \\begin{equation*} R^A_{BF} = AR_{BF} + SR_{BF} = \\sum\\limits_{i=1}^{I}(w_i^P - w_i^B)(r_i^B - R^B) + \\sum\\limits_{i=1}^{I}w_i^P(r_i^P - r_i^B) \\end{equation*} $$\n下面，我们开始\nReference: 《“星火”多因子专题报告（四） —— 基于持仓的基金业绩归因：始于 Brinson，归于 Barra》，财通证券。\n","date":"July 23, 2024","hero":"/posts/quant/multi-factors/perf-attri/images/boat.jpg","permalink":"https://online727.github.io/cn/posts/quant/multi-factors/perf-attri/","summary":"1. 摘要 投资组合的业绩归因可以分为 收益归因 和 风险归因 两个部分，而归因又可以基于净值或持仓进行。本文主要基于 持仓数据 对组合的业绩归因进行探讨。\n在组合收益归因方面，主要有以下部分：\n基于 Brinson 模型 经典版 BHB (Brinson, Hood and Beebower) 模型：将组合超额收益分解为配置收益、选股收益和交互收益 3 部分。 改进版 BF (Brinson and Fachler) 模型：引入行业超额收益，将组合超额收益分解为配置效应和选股效应两个部分。 基于多因子模型 基于行业的多因子收益归因：与自下而上的 Brinson 模型完全一致。 基于行业和风格的多因子收益归因：同时对行业和风格上的配置进行分析。 在组合风险归因方面，主要基于多因子模型：\n单一波动分解法：单独考虑每个因子，计算简单，但忽略因子之间的协同影响，且不具可加性。 边际风险分解法：将组合风险分解为因子暴露度与因子边际风险贡献的乘积，然而偏导数的概念相对模糊，指导意义不强。 三要素分解法：将风险分解为因子暴露 ($x$)、因子波动 ($\\sigma$) 和因子-组合相关系数 ($\\rho$)，对风险的分解更为透彻，更有利于投资经理对风险进行控制。 2. 基于 Brinson 模型的组合收益归因 2.1 经典 BHB 模型 BHB 模型将投资组合的超额收益率分解为 配置收益、选股收益和交互收益 三个部分，其基本框架如下图所示，其中红色渲染部分表示投资组合的超额收益。\n从行业配置的角度而言，假设 $w_{i}^{P}, w_{i}^{B}$ 分别表示投资组合和基准组合中行业 $i$ 的权重，$r_{i}^{P}, r_{i}^{B}$ 分别表示投资组合和基准组合中行业 $i$ 的收益率，那么投资组合的收益率 $R^{P}$ 和基准组合的收益率 $R^{B}$ 就可以表示为： $$ \\begin{align*} R^{P}\u0026amp;=\\sum_{i=1}^{I}w_{i}^{P}r_{i}^{P}, where\\sum_{i=1}^{I}w_{i}^{P}=1 \\cr R^{B}\u0026amp;=\\sum_{i=1}^{I}w_{i}^{B}r_{i}^{B}, where\\sum_{i=1}^{I}w_{i}^{B}=1 \\end{align*} $$","tags":["绩效归因","多因子模型"],"title":"多因子绩效归因"}]