<!doctype html><html lang=en><head><title>Questions of Assumptions</title>
<meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/application.d60808555b3afbcfaf18c23a60e08a98667faa5a60879f6703a355b38eafb832.css integrity="sha256-1ggIVVs6+8+vGMI6YOCKmGZ/qlpgh59nA6NVs46vuDI="><link rel=icon type=image/png href=/images/site/favicon_hu8414222332455362891.png><meta property="og:url" content="https://online727.github.io/posts/linear_models/lr_quant/lr_assumptions/"><meta property="og:site_name" content="Haohan's Blog"><meta property="og:title" content="Questions of Assumptions"><meta property="og:description" content="Linear Regression Questions regarding Assumptions"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-11-26T12:00:25+08:00"><meta property="article:modified_time" content="2024-11-26T12:00:25+08:00"><meta property="article:tag" content="Linear Model"><meta property="article:tag" content="Linear Regression"><meta property="article:tag" content="Quant"><meta name=twitter:card content="summary"><meta name=twitter:title content="Questions of Assumptions"><meta name=twitter:description content="Linear Regression Questions regarding Assumptions"><meta name=description content="Linear Regression Questions regarding Assumptions"><script>theme=localStorage.getItem("theme-scheme")||localStorage.getItem("darkmode:color-scheme")||"light",theme=="system"&&(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?theme="dark":theme="light"),document.documentElement.setAttribute("data-theme",theme)</script></head><body class="type-posts kind-page" data-bs-spy=scroll data-bs-target=#TableOfContents data-bs-offset=80><div class="container-fluid bg-secondary wrapper"><nav class="navbar navbar-expand-xl top-navbar shadow" id=top-navbar><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button>
<i data-feather=sidebar></i>
</button>
<a class=navbar-brand href=/><img src=/images/site/main-logo_hu10708377409321002774.png id=logo alt=Logo>
Haohan's Blog</a>
<button class="navbar-toggler navbar-light" id=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#top-nav-items aria-label=menu>
<i data-feather=menu></i></button><div class="collapse navbar-collapse dynamic-navbar" id=top-nav-items><ul class="nav navbar-nav ms-auto"><li class=nav-item><a class=nav-link href=/#home>Home</a></li><li class=nav-item><a class=nav-link href=/#about>About</a></li><li class=nav-item><a class=nav-link href=/#education>Education</a></li><li class=nav-item><a class=nav-link href=/#experiences>Experiences</a></li><li class=nav-item><a class=nav-link href=/#projects>Projects</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>More</a><div class=dropdown-menu aria-labelledby=navbarDropdown><a class=dropdown-item href=/#skills>Skills</a>
<a class=dropdown-item href=/#featured-posts>Featured Posts</a>
<a class=dropdown-item href=/#recent-posts>Recent Posts</a>
<a class=dropdown-item href=/#accomplishments>Accomplishments</a></div></li><div id=top-navbar-divider></div><li class=nav-item><a class=nav-link id=blog-link href=/posts>Posts</a></li><li class=nav-item><a class=nav-link id=note-link href=/notes>Notes</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=languageSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="fi fi-gb"></span>
English</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/posts/linear_models/lr_quant/lr_assumptions><span class="fi fi-gb"></span>
English
</a><a class="dropdown-item nav-link languages-item" href=/cn/posts/linear_models/lr_quant/lr_assumptions><span class="fi fi-cn"></span>
简体中文</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme"></a><div id=themeMenu class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# data-scheme=light><img class=theme-icon src=/icons/sun-svgrepo-com.svg width=20 alt="Light Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=dark><img class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=system><img class=theme-icon src=/icons/computer-svgrepo-com.svg width=20 alt="System Theme"></a></div></li></ul></div></div><img src=/images/site/main-logo_hu10708377409321002774.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu8414222332455362891.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts/ data-filter=all>Posts</a></li><div class=subtree><li><i data-feather=plus-circle></i><a class=list-link href=/posts/example/> Examples</a><ul><li><a class=list-link href=/posts/example/introduction/ title=Introduction>Introduction</a></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/example/category/> Category</a><ul><li><i data-feather=plus-circle></i><a class=list-link href=/posts/example/category/sub-category/> Sub-Category</a><ul><li><a class=list-link href=/posts/example/category/sub-category/rich-content/ title="Rich Content">Rich Content</a></li></ul></li></ul></li><li><a class=list-link href=/posts/example/markdown-sample/ title="Markdown Sample">Markdown Sample</a></li><li><a class=list-link href=/posts/example/shortcodes/ title="Shortcodes Sample">Shortcodes Sample</a></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/dltorch/> Deep Learning (Pytorch)</a><ul><li><a class=list-link href=/posts/dltorch/ch2/ title="Chapter 2 Preparation">Chapter 2 Preparation</a></li><li><a class=list-link href=/posts/dltorch/ch3/ title="Chapter 3 Linear Regression">Chapter 3 Linear Regression</a></li><li><a class=list-link href=/posts/dltorch/ch4/ title="Chapter 4 Multilayer Perceptrons">Chapter 4 Multilayer Perceptrons</a></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/quant/> Quant</a><ul><li><i data-feather=plus-circle></i><a class=list-link href=/posts/quant/multi-factors/> Multi-Factors Model</a><ul><li><a class=list-link href=/posts/quant/multi-factors/perf-attri/ title="Performance Attribution">Performance Attribution</a></li></ul></li></ul></li><li><i data-feather=minus-circle></i><a class="active list-link" href=/posts/linear_models/> Linear Models</a><ul class=active><li><a class=list-link href=/posts/linear_models/lr/ title="Linear Regression">Linear Regression</a></li><li><i data-feather=minus-circle></i><a class="active list-link" href=/posts/linear_models/lr_quant/> Linear Regression in Quant</a><ul class=active><li><a class=list-link href=/posts/linear_models/lr_quant/lr_conceptions/ title=Conceptions>Conceptions</a></li><li><a class="active list-link" href=/posts/linear_models/lr_quant/lr_assumptions/ title=Assumptions>Assumptions</a></li><li><a class=list-link href=/posts/linear_models/lr_quant/lr_coefficients/ title=Coefficients>Coefficients</a></li><li><a class=list-link href=/posts/linear_models/lr_quant/lr_r2/ title="R Square">R Square</a></li></ul></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/matrix_cookbook/> Matrix Cookbook</a><ul><li><i data-feather=plus-circle></i><a class=list-link href=/posts/matrix_cookbook/basic/> Matrix Basic</a><ul><li><a class=list-link href=/posts/matrix_cookbook/basic/notations/ title=Notations>Notations</a></li><li><a class=list-link href=/posts/matrix_cookbook/basic/basic_content/ title=Basics>Basics</a></li></ul></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/sky.jpg)></div><div class=page-content><div class="author-profile ms-auto align-self-lg-center"><img class=rounded-circle src=/images/author/zhh_hu2277249603137709564.png alt="Author Image"><h5 class=author-name>Haohan Zhao</h5><p class=text-muted>Tuesday, November 26, 2024 | 7 minutes</p></div><div class=title><h1>Questions of Assumptions</h1></div><div class=tags><ul style=padding-left:0><li class=rounded><a href=/tags/linear-model/ class="btn btn-sm btn-info">Linear Model</a></li><li class=rounded><a href=/tags/linear-regression/ class="btn btn-sm btn-info">Linear Regression</a></li><li class=rounded><a href=/tags/quant/ class="btn btn-sm btn-info">Quant</a></li></ul></div><div class=post-content id=post-content><ol><li>$y\sim(1,\boldsymbol{x})$, regress $y$ on $x$ with intercept.</li><li>$y\sim(\boldsymbol{x})$, regress $y$ on $x$ without intercept.</li><li>In the context of Statistics, SSE (Sum of Squares due to Error) and SSR (Sum of Squares due to Regression) are used more frequently. But in Economitrics, ESS (Explained Sum of Squares) and RSS (Residual Sum of Squares) are prefered.</li></ol><h3 id=01-heteroskedasticity-and-autocorrelation>0.1 Heteroskedasticity and Autocorrelation</h3><p>If the residuals ($\epsilon$) in a linear regression model exhibit heteroskedasticity (non-constant variance) or autocorrelation (correlation between residuals across observations), how will it impact the estimation and inference of $\beta$? How to test and solve these problems?</p><p>I&rsquo;ve discusses this question in <a href=../../lr/index.html>Linear Regression</a>.</p><h4 id=011-impact-on-beta-estimation>0.1.1 Impact on $\beta$ Estimation</h4><ol><li><p><strong>Heteroskedasticity</strong>:</p><ul><li>The OLS estimator of $\beta$ remains <strong>unbiased</strong> and <strong>consistent</strong>, but it is no longer <strong>efficient</strong> (i.e., it does not have the minimum variance among linear unbiased estimators).</li><li>The usual standard errors are incorrect, leading to unreliable hypothesis tests and confidence intervals.</li></ul></li><li><p><strong>Autocorrelation</strong>:</p><ul><li>Similar to heteroskedasticity, the OLS estimator remains <strong>unbiased</strong> and <strong>consistent</strong>, but it is <strong>inefficient</strong> when autocorrelation is present.</li><li>Autocorrelation inflates or deflates the standard errors, resulting in incorrect $t$-statistics and $p$-values for hypothesis testing.</li></ul></li></ol><h4 id=012-diagnostic-tests>0.1.2 Diagnostic Tests</h4><ol><li><p><strong>For Heteroskedasticity</strong>:</p><ul><li><strong>Breusch-Pagan Test</strong>: Tests whether the residual variance is dependent on the values of independent variables.</li><li><strong>White’s Test</strong>: A more general test that detects any form of heteroskedasticity, including non-linear relationships.</li><li><strong>Residual Plot</strong>: Plot residuals against fitted values. If the spread increases or decreases systematically, it suggests heteroskedasticity.</li></ul></li><li><p><strong>For Autocorrelation</strong>:</p><ul><li><strong>Durbin-Watson Test</strong>: Tests for the presence of first-order autocorrelation.</li><li><strong>Breusch-Godfrey Test</strong>: Tests for higher-order autocorrelation.</li><li><strong>Residual Plot</strong>: Plot residuals against time or another ordering variable to visually inspect patterns.</li></ul></li></ol><h4 id=013-solutions>0.1.3 Solutions</h4><ol><li><p><strong>For Heteroskedasticity</strong>:</p><ul><li>Use <strong>robust standard errors</strong> (e.g., White or HC standard errors) to correct for heteroskedasticity in inference.</li><li>Apply <strong>Weighted Least Squares (WLS)</strong>: Reweight observations based on the inverse of the variance of the residuals.</li><li>Transform the data: Log or square root transformations can stabilize variance in some cases.</li></ul></li><li><p><strong>For Autocorrelation</strong>:</p><ul><li>Use <strong>Newey-West standard errors</strong> to adjust for autocorrelation and heteroskedasticity.</li><li>Apply <strong>Generalized Least Squares (GLS)</strong>: Models the structure of autocorrelation and heteroskedasticity explicitly.</li><li>Add lagged dependent variables or other time-series-specific features to the model to capture the autocorrelation structure.</li></ul></li></ol><h4 id=014-summary-table>0.1.4 Summary Table</h4><table><thead><tr><th>Issue</th><th>Effect on $\beta$ Estimator</th><th>Key Tests</th><th>Solutions</th></tr></thead><tbody><tr><td>Heteroskedasticity</td><td>Unbiased, inconsistent SEs</td><td>Breusch-Pagan, White</td><td>Robust SEs, WLS, transformations</td></tr><tr><td>Autocorrelation</td><td>Unbiased, inconsistent SEs</td><td>Durbin-Watson, Breusch-Godfrey</td><td>Newey-West SEs, GLS, model adjustments</td></tr></tbody></table><h3 id=02-multicollinearity>0.2 Multicollinearity</h3><ul><li>Bad influences<ul><li>Larger values of OLS estamators&rsquo; variance and standard error.</li><li>Wider confidence interval.</li><li>Not significant t-value.</li><li>Higher $R^{2}$ but not all t values are significant.</li><li>Not robust, sensitive to the small change of data.</li></ul></li><li>Diagnoses<ul><li>Higher $R^{2}$ but the number of significant t values is small.</li><li>High correlation between variables.</li><li>Partial correlation coefficient.</li><li>Subsidiary or auxiliary regression, and test $R^{2}_{i}$.</li><li>Variance inflation factor VIF: $VIF=\frac{1}{1-R^{2}_{i}}$.</li></ul></li><li>Solutions<ul><li>Delete some variables.</li><li>More new data.</li><li>Reset model.</li><li>Variable transformation.</li><li>Factor analysis / principal component analysis / ridge regression / LASSO</li></ul></li></ul><h3 id=03-heavy-tail-of-y>0.3 Heavy Tail of $y$</h3><h4 id=031-issues>0.3.1 Issues</h4><ul><li><strong>Sensitivity in Parameter Estimation</strong><ul><li><strong>Problem</strong>: Linear regression typically uses Ordinary Least Squares (OLS) to estimate coefficients, which minimizes the sum of squared residuals. Heavy-tailed distributions often include extreme values (outliers), which disproportionately influence the regression estimates.</li><li><strong>Cause</strong>: OLS is highly sensitive to large residuals because the squared term amplifies their impact.</li><li><strong>Consequence</strong>: The regression coefficients can deviate significantly from their true values, reducing the model&rsquo;s reliability in capturing the overall trend.</li></ul></li><li><strong>Reduced Robustness of the Model</strong><ul><li><strong>Problem</strong>: With heavy-tailed $y$, the model might overfit to extreme values, losing its ability to represent the central trend of the data.</li><li><strong>Cause</strong>: The extreme observations exert an outsized influence on the regression line, potentially leading to distorted predictions.</li><li><strong>Consequence</strong>: The model may perform well on training data but fail to generalize effectively to new data.</li></ul></li><li><strong>Increased Prediction Error</strong><ul><li><strong>Problem</strong>: Heavy tails in $y$ imply a higher probability of extreme values. The regression model struggles to predict these values accurately.</li><li><strong>Cause</strong>: Linear regression assumes normally distributed errors, which is incompatible with heavy-tailed distributions, leading to larger prediction deviations.</li><li><strong>Consequence</strong>: Metrics like Mean Squared Error (MSE) may increase, and the model&rsquo;s practical utility can diminish.</li></ul></li><li><strong>Invalid Diagnostic Tools</strong><ul><li><strong>Problem</strong>: Many diagnostic tools for linear regression, such as $R^2$ or residual normality checks, rely on the assumption of normally distributed residuals. Heavy-tailed $y$ may violate these assumptions.</li><li><strong>Cause</strong>: The non-normal distribution of residuals undermines standard hypothesis tests (e.g., $t$-tests, $F$-tests) and model validation methods.</li><li><strong>Consequence</strong>: Misleading results in assessing model significance or goodness-of-fit.</li></ul></li><li><strong>Decreased Interpretability</strong><ul><li><strong>Problem</strong>: Heavy-tailed $y$ often leads to inflated or deflated regression coefficients, making it harder to interpret their relationship with predictors.</li><li><strong>Cause</strong>: Extreme values have high leverage in OLS, skewing coefficient estimates away from their representative values.</li><li><strong>Consequence</strong>: The economic or statistical interpretation of the model becomes unreliable.</li></ul></li></ul><h4 id=032-solutions>0.3.2 Solutions</h4><ul><li><strong>Transform the Target Variable</strong>:<ul><li>Apply transformations like log-transform or Box-Cox to reduce the impact of heavy tails.</li></ul></li><li><strong>Use Robust Regression Methods</strong>:<ul><li>Replace OLS with <strong>Huber Regression</strong>, <strong>Quantile Regression</strong>, or <strong>Theil-Sen Regression</strong>, which are less sensitive to outliers.</li></ul></li><li><strong>Detect and Address Outliers</strong>:<ul><li>Preprocess the data by identifying and handling extreme values through trimming, winsorizing, or imputation.</li></ul></li><li><strong>Adopt Models with Weaker Distributional Assumptions</strong>:<ul><li>Use non-parametric methods such as Gradient Boosting Machines (GBMs) or Random Forests, which do not rely on specific error distributions.</li></ul></li><li><strong>Leverage Extreme Value Theory (EVT)</strong>:<ul><li>For cases where heavy tails are intrinsic to the data, use EVT to explicitly model extreme values.</li></ul></li></ul><h3 id=04-heavy-tail-of-x>0.4 Heavy Tail of $x$</h3><h4 id=041-issues>0.4.1 Issues</h4><ul><li><strong>Sensitivity to Leverage Points</strong><ul><li><strong>Problem</strong>: In linear regression, extreme values in $x$ (caused by heavy tails) can act as high-leverage points, disproportionately influencing the regression line.</li><li><strong>Cause</strong>: Observations with extreme $x$-values have more &ldquo;leverage&rdquo; in determining the slope and intercept of the regression line.</li><li><strong>Consequence</strong>: This can lead to biased or unstable estimates of regression coefficients, especially when the number of such points is small.</li></ul></li><li><strong>Increased Variance in Coefficient Estimates</strong><ul><li><strong>Problem</strong>: Heavy-tailed $x$ increases the variability in the estimation of regression coefficients.</li><li><strong>Cause</strong>: The large variability in $x$ inflates the denominator in variance calculations for the OLS estimates, leading to higher uncertainty.</li><li><strong>Consequence</strong>: Confidence intervals for the coefficients may widen, and statistical tests for significance (e.g., $t$-tests) become less reliable.</li></ul></li><li><strong>Violated Assumptions</strong><ul><li><strong>Problem</strong>: The heavy-tailed distribution of $x$ may violate linear regression assumptions, particularly those related to the design matrix.</li><li><strong>Cause</strong>:<ul><li>The heavy-tailed $x$ may not adequately represent the predictor space, violating the assumption of a well-conditioned matrix.</li><li>Extreme values in $x$ can create multicollinearity problems when combined with other predictors.</li></ul></li><li><strong>Consequence</strong>: Regression estimates may become unstable or non-invertible (e.g., if the design matrix becomes ill-conditioned).</li></ul></li><li><strong>Overemphasis on Extreme Values</strong><ul><li><strong>Problem</strong>: The model may overfit to observations with extreme $x$-values.</li><li><strong>Cause</strong>: Since OLS minimizes the residual sum of squares, extreme $x$-values amplify the influence of corresponding residuals.</li><li><strong>Consequence</strong>: The regression line might be skewed toward capturing trends in extreme $x$-values rather than the majority of the data.</li></ul></li><li><strong>Interpretability Challenges</strong><ul><li><strong>Problem</strong>: Heavy-tailed $x$ can distort the interpretability of regression coefficients.</li><li><strong>Cause</strong>: Extreme $x$-values may represent atypical or non-representative scenarios, leading to coefficients that do not reflect the central tendency of the data.</li><li><strong>Consequence</strong>: The model&rsquo;s explanatory power for the bulk of the data may decrease, and coefficients may lose practical significance.</li></ul></li></ul><h4 id=042-solutions>0.4.2 Solutions</h4><ul><li><strong>Transform $x$</strong>:<ul><li>Apply transformations like log-transform or Winsorization to reduce the impact of heavy tails in $x$.</li></ul></li><li><strong>Robust Regression</strong>:<ul><li>Use robust regression methods, such as Huber Regression or Ridge Regression, which can mitigate the influence of extreme $x $-values.</li></ul></li><li><strong>Regularization</strong>:<ul><li>Techniques like Lasso or Ridge Regression can help stabilize coefficient estimates by adding penalties that prevent overemphasis on extreme $x$-values.</li></ul></li><li><strong>Identify and Handle Leverage Points</strong>:<ul><li>Diagnose high-leverage points using metrics like Cook&rsquo;s Distance or leverage statistics, and consider removing or down-weighting these points.</li></ul></li><li><strong>Alternative Models</strong>:<ul><li>Use models that are less sensitive to extreme $x $-values, such as decision trees, random forests, or gradient boosting machines.</li></ul></li></ul></div><div class="row ps-3 pe-3"><div class="col-md-6 share-buttons"><strong>Share on:</strong>
<a class="btn icon-button bg-facebook" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_assumptions%2f" target=_blank><i class="fab fa-facebook"></i>
</a><a class="btn icon-button bg-twitter" href="https://twitter.com/share?url=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_assumptions%2f&text=Questions%20of%20Assumptions&via=Haohan%27s%20Blog" target=_blank><i class="fab fa-twitter"></i>
</a><a class="btn icon-button bg-reddit" href="https://reddit.com/submit?url=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_assumptions%2f&title=Questions%20of%20Assumptions" target=_blank><i class="fab fa-reddit"></i>
</a><a class="btn icon-button bg-linkedin" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_assumptions%2f&title=Questions%20of%20Assumptions" target=_blank><i class="fab fa-linkedin"></i>
</a><a class="btn icon-button bg-whatsapp" href="https://api.whatsapp.com/send?text=Questions%20of%20Assumptions https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_assumptions%2f" target=_blank><i class="fab fa-whatsapp"></i>
</a><a class="btn icon-button" href="mailto:?subject=Questions%20of%20Assumptions&body=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_assumptions%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div><div class="col-md-6 btn-improve-page"><a href=https://github.com/online727/online727.github.io/edit/main/content/posts/linear_models/lr_quant/lr_assumptions/index.md title="Improve this page" target=_blank rel=noopener><i class="fas fa-code-branch"></i>
Improve this page</a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/posts/linear_models/lr_quant/lr_conceptions/ title="Questions of Conceptions" class="btn filled-button"><div><i class="fas fa-chevron-circle-left"></i> Prev</div><div class=next-prev-text>Questions of Conceptions</div></a></div><div class="col-md-6 next-article"><a href=/posts/linear_models/lr_quant/lr_coefficients/ title="Questions of Coefficients" class="btn filled-button"><div>Next <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>Questions of Coefficients</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn type=button data-bs-toggle=tooltip data-bs-placement=left title="Scroll to top"><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center ps-3">Table of Contents</h5><hr><div class=toc><nav id=TableOfContents><ul><li><ul><li><a href=#01-heteroskedasticity-and-autocorrelation>0.1 Heteroskedasticity and Autocorrelation</a><ul><li><a href=#011-impact-on-beta-estimation>0.1.1 Impact on $\beta$ Estimation</a></li><li><a href=#012-diagnostic-tests>0.1.2 Diagnostic Tests</a></li><li><a href=#013-solutions>0.1.3 Solutions</a></li><li><a href=#014-summary-table>0.1.4 Summary Table</a></li></ul></li><li><a href=#02-multicollinearity>0.2 Multicollinearity</a></li><li><a href=#03-heavy-tail-of-y>0.3 Heavy Tail of $y$</a><ul><li><a href=#031-issues>0.3.1 Issues</a></li><li><a href=#032-solutions>0.3.2 Solutions</a></li></ul></li><li><a href=#04-heavy-tail-of-x>0.4 Heavy Tail of $x$</a><ul><li><a href=#041-issues>0.4.1 Issues</a></li><li><a href=#042-solutions>0.4.2 Solutions</a></li></ul></li></ul></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-start"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#education>Education</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#experiences>Experiences</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#skills>Skills</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#featured-posts>Featured Posts</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#recent-posts>Recent Posts</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#accomplishments>Accomplishments</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:zhhohoh27@gamil.com target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>zhhohoh27@gamil.com</span></a></li><li><a href=https://github.com/online727 target=_blank rel=noopener><span><i class="fab fa-github"></i></span> <span>online727</span></a></li><li><a href=https://www.linkedin.com/in/haohan-zhao-9a6b24296 target=_blank rel=noopener><span><i class="fab fa-linkedin"></i></span> <span>Haohan Zhao</span></a></li><li><span><i class="fas fa-phone-alt"></i></span> <span>+86 19551998168</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>Liability Notice:</strong> This site is built on hugo and github pages and uses the hugo-toha theme. The site is used for personal blogging, all content is owned by me and does not constitute any relevant advice, if you have any questions, please contact me!</p></div><hr><div class=container><div class="row text-start"><div class=col-md-4><a id=theme href=https://github.com/hugo-toha/toha target=_blank rel=noopener><img src=/images/theme-logo_hu16779671404603505019.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2020 Copyright.</div><div class="col-md-4 text-end"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/application.aa1b29568827d862abc07cd2a25fa9f3f1dad96fd8fe2a012bccae2de39367fc.js integrity="sha256-qhspVogn2GKrwHzSol+p8/Ha2W/Y/ioBK8yuLeOTZ/w=" defer></script></body></html>