<!doctype html><html lang=en><head><title>Questions of Conceptions</title>
<meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><link rel=stylesheet href=/application.d60808555b3afbcfaf18c23a60e08a98667faa5a60879f6703a355b38eafb832.css integrity="sha256-1ggIVVs6+8+vGMI6YOCKmGZ/qlpgh59nA6NVs46vuDI="><link rel=icon type=image/png href=/images/site/favicon_hu8414222332455362891.png><meta property="og:url" content="https://online727.github.io/posts/linear_models/lr_quant/lr_conceptions/"><meta property="og:site_name" content="Haohan's Blog"><meta property="og:title" content="Questions of Conceptions"><meta property="og:description" content="Linear Regression Questions regarding Conceptions"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-11-16T11:45:25+08:00"><meta property="article:modified_time" content="2024-11-16T11:45:25+08:00"><meta property="article:tag" content="Linear Model"><meta property="article:tag" content="Linear Regression"><meta property="article:tag" content="Quant"><meta name=twitter:card content="summary"><meta name=twitter:title content="Questions of Conceptions"><meta name=twitter:description content="Linear Regression Questions regarding Conceptions"><meta name=description content="Linear Regression Questions regarding Conceptions"><script>theme=localStorage.getItem("theme-scheme")||localStorage.getItem("darkmode:color-scheme")||"light",theme=="system"&&(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?theme="dark":theme="light"),document.documentElement.setAttribute("data-theme",theme)</script></head><body class="type-posts kind-page" data-bs-spy=scroll data-bs-target=#TableOfContents data-bs-offset=80><div class="container-fluid bg-secondary wrapper"><nav class="navbar navbar-expand-xl top-navbar shadow" id=top-navbar><div class=container><button class="navbar-toggler navbar-light" id=sidebar-toggler type=button>
<i data-feather=sidebar></i>
</button>
<a class=navbar-brand href=/><img src=/images/site/main-logo_hu10708377409321002774.png id=logo alt=Logo>
Haohan's Blog</a>
<button class="navbar-toggler navbar-light" id=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#top-nav-items aria-label=menu>
<i data-feather=menu></i></button><div class="collapse navbar-collapse dynamic-navbar" id=top-nav-items><ul class="nav navbar-nav ms-auto"><li class=nav-item><a class=nav-link href=/#home>Home</a></li><li class=nav-item><a class=nav-link href=/#about>About</a></li><li class=nav-item><a class=nav-link href=/#education>Education</a></li><li class=nav-item><a class=nav-link href=/#experiences>Experiences</a></li><li class=nav-item><a class=nav-link href=/#projects>Projects</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>More</a><div class=dropdown-menu aria-labelledby=navbarDropdown><a class=dropdown-item href=/#skills>Skills</a>
<a class=dropdown-item href=/#featured-posts>Featured Posts</a>
<a class=dropdown-item href=/#recent-posts>Recent Posts</a>
<a class=dropdown-item href=/#accomplishments>Accomplishments</a></div></li><div id=top-navbar-divider></div><li class=nav-item><a class=nav-link id=blog-link href=/posts>Posts</a></li><li class=nav-item><a class=nav-link id=note-link href=/notes>Notes</a></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=languageSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><span class="fi fi-gb"></span>
English</a><div class=dropdown-menu aria-labelledby=languageSelector><a class="dropdown-item nav-link languages-item" href=/posts/linear_models/lr_quant/lr_conceptions><span class="fi fi-gb"></span>
English
</a><a class="dropdown-item nav-link languages-item" href=/cn/posts/linear_models/lr_quant/lr_conceptions><span class="fi fi-cn"></span>
简体中文</a></div></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href=# id=themeSelector role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false><img id=navbar-theme-icon-svg class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme"></a><div id=themeMenu class="dropdown-menu dropdown-menu-icons-only" aria-labelledby=themeSelector><a class="dropdown-item nav-link" href=# data-scheme=light><img class=theme-icon src=/icons/sun-svgrepo-com.svg width=20 alt="Light Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=dark><img class=theme-icon src=/icons/moon-svgrepo-com.svg width=20 alt="Dark Theme">
</a><a class="dropdown-item nav-link" href=# data-scheme=system><img class=theme-icon src=/icons/computer-svgrepo-com.svg width=20 alt="System Theme"></a></div></li></ul></div></div><img src=/images/site/main-logo_hu10708377409321002774.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/inverted-logo_hu8414222332455362891.png class=d-none id=inverted-logo alt="Inverted Logo"></nav><section class=sidebar-section id=sidebar-section><div class=sidebar-holder><div class=sidebar id=sidebar><form class=mx-auto method=get action=/search><input type=text name=keyword placeholder=Search data-search id=search-box></form><div class=sidebar-tree><ul class=tree id=tree><li id=list-heading><a href=/posts/ data-filter=all>Posts</a></li><div class=subtree><li><i data-feather=plus-circle></i><a class=list-link href=/posts/example/> Examples</a><ul><li><a class=list-link href=/posts/example/introduction/ title=Introduction>Introduction</a></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/example/category/> Category</a><ul><li><i data-feather=plus-circle></i><a class=list-link href=/posts/example/category/sub-category/> Sub-Category</a><ul><li><a class=list-link href=/posts/example/category/sub-category/rich-content/ title="Rich Content">Rich Content</a></li></ul></li></ul></li><li><a class=list-link href=/posts/example/markdown-sample/ title="Markdown Sample">Markdown Sample</a></li><li><a class=list-link href=/posts/example/shortcodes/ title="Shortcodes Sample">Shortcodes Sample</a></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/dltorch/> Deep Learning (Pytorch)</a><ul><li><a class=list-link href=/posts/dltorch/ch2/ title="Chapter 2 Preparation">Chapter 2 Preparation</a></li><li><a class=list-link href=/posts/dltorch/ch3/ title="Chapter 3 Linear Regression">Chapter 3 Linear Regression</a></li><li><a class=list-link href=/posts/dltorch/ch4/ title="Chapter 4 Multilayer Perceptrons">Chapter 4 Multilayer Perceptrons</a></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/quant/> Quant</a><ul><li><i data-feather=plus-circle></i><a class=list-link href=/posts/quant/multi-factors/> Multi-Factors Model</a><ul><li><a class=list-link href=/posts/quant/multi-factors/perf-attri/ title="Performance Attribution">Performance Attribution</a></li></ul></li></ul></li><li><i data-feather=minus-circle></i><a class="active list-link" href=/posts/linear_models/> Linear Models</a><ul class=active><li><a class=list-link href=/posts/linear_models/lr/ title="Linear Regression">Linear Regression</a></li><li><i data-feather=minus-circle></i><a class="active list-link" href=/posts/linear_models/lr_quant/> Linear Regression in Quant</a><ul class=active><li><a class="active list-link" href=/posts/linear_models/lr_quant/lr_conceptions/ title=Conceptions>Conceptions</a></li><li><a class=list-link href=/posts/linear_models/lr_quant/lr_assumptions/ title=Assumptions>Assumptions</a></li><li><a class=list-link href=/posts/linear_models/lr_quant/lr_coefficients/ title=Coefficients>Coefficients</a></li><li><a class=list-link href=/posts/linear_models/lr_quant/lr_r2/ title="R Square">R Square</a></li></ul></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/matrix_cookbook/> Matrix Cookbook</a><ul><li><i data-feather=plus-circle></i><a class=list-link href=/posts/matrix_cookbook/basic/> Matrix Basic</a><ul><li><a class=list-link href=/posts/matrix_cookbook/basic/notations/ title=Notations>Notations</a></li><li><a class=list-link href=/posts/matrix_cookbook/basic/basic_content/ title=Basics>Basics</a></li></ul></li></ul></li><li><i data-feather=plus-circle></i><a class=list-link href=/posts/tips/> Tips</a><ul><li><i data-feather=plus-circle></i><a class=list-link href=/posts/tips/ubuntu/> Ubuntu</a><ul><li><a class=list-link href=/posts/tips/ubuntu/easyconnect/ title=Easyconnect>Easyconnect</a></li></ul></li></ul></li></div></ul></div></div></div></section><section class=content-section id=content-section><div class=content><div class="container p-0 read-area"><div class="hero-area col-sm-12" id=hero-area style=background-image:url(/images/sky.jpg)></div><div class=page-content><div class="author-profile ms-auto align-self-lg-center"><img class=rounded-circle src=/images/author/zhh_hu2277249603137709564.png alt="Author Image"><h5 class=author-name>Haohan Zhao</h5><p class=text-muted>Saturday, November 16, 2024 | 5 minutes</p></div><div class=title><h1>Questions of Conceptions</h1></div><div class=tags><ul style=padding-left:0><li class=rounded><a href=/tags/linear-model/ class="btn btn-sm btn-info">Linear Model</a></li><li class=rounded><a href=/tags/linear-regression/ class="btn btn-sm btn-info">Linear Regression</a></li><li class=rounded><a href=/tags/quant/ class="btn btn-sm btn-info">Quant</a></li></ul></div><div class=post-content id=post-content><p>With reference to <a href=https://zhuanlan.zhihu.com/p/443658898 target=_blank rel=noopener>donggua</a>.</p><p>I complete the answers of these questions.</p><h2 id=01-notations>0.1 Notations</h2><ol><li>$y\sim(1,\boldsymbol{x})$, regress $y$ on $x$ with intercept.</li><li>$y\sim(\boldsymbol{x})$, regress $y$ on $x$ without intercept.</li><li>In the context of Statistics, SSE (Sum of Squares due to Error) and SSR (Sum of Squares due to Regression) are used more frequently. But in Economitrics, ESS (Explained Sum of Squares) and RSS (Residual Sum of Squares) are prefered.</li></ol><h2 id=02-conceptions-and-basic-definitions>0.2 Conceptions and Basic Definitions</h2><h5 id=021-the-assumptions-of-lr>0.2.1. The assumptions of LR</h5><p><strong>Gauss-Markov Theory</strong>: Under the assumptions of classical linear regression, the ordinary least squares (OLS) estimator is the linear unviased estimator with the minimum variance. <strong>(BLUE)</strong></p><ol><li><strong>Linear in Parameters</strong>: The model in the population can be written as:
$$
y=\beta_0 + \beta_1x_1 + \beta_2x_2 + \cdots + \beta_k x_k + u
$$
where $\beta_1,\beta_2,\cdots,\beta_k$ are the unknown parameters (constants) of interest and $u$ is an unobservable random error or disturbance term.</li><li><strong>Random Sampling</strong>: We have a random sample of $N$ observations, ${(x_{i1}, x_{i2}, \cdots, x_{ik}, y_i)}_{i=1}^N$ following the population model defined in assumption 1.</li><li><strong>No Perfect Collinearity</strong>: In the sample (and therefore in the population), none of the independent variables is constant, and there are no exact linear relationships among the independent variables.</li><li><strong>Zero Conditional Mean</strong>: The error $u$ has an expected value of zero given any value of the independent variables. In the other words, $E(u|x_1,x_2,\cdots,x_k)=0$.</li><li><strong>Homoskedasticity</strong>: The error $u_i$ has the same variance given any values of the explanatory variables. In other words, $E(u_i^2|x_1,x_2,\cdots,x_k)=\sigma^2$.</li><li><strong>Normality</strong>: The population error $u$ is independent of the explanatory variables $x_1,x_2,\cdots,x_k$ and is normally distributed with zero mean and constant variance: $u\sim N(0,\mu)$.</li></ol><p>The properties of OLS estimators: <strong>Best Linear Unbiased Estimators (BLUEs)</strong>: they have smallest variance among all linear unbiased estimators. These properties only need the first 5 assumptions to be proved (Unbiased only needs the first 4 assumptions). The 6.th assumption is only utilized when conducting hypothesis testing on the parameters.</p><h5 id=022-the-loss-function-of-lr-and-why-we-choose-it>0.2.2 The loss function of LR and why we choose it?</h5><p><strong>MSE (Mean Square Error)</strong> is the most frequently used loss function (optimization objection) of OLS. What&rsquo;s more, <strong>MAE (Mean Absolute Error)</strong> is also used is some situations.
$$
MSE = \frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{n}, \quad MAE = \frac{\sum_{i=1}^n|y_i-\hat{y}_i|}{n}
$$</p><p>Compared to MAE, MSE has many good properties:</p><ul><li><strong>Unique optimal solution</strong>: For the least squares method, as long as the variables are not multicollinear, the solution is unique. However, for the least absolute deviation method, the solution is not fixed. For example, if there are no independent variables (only the dependent variable $y$), the least squares method predicts the <strong>mean</strong> of $y$, while the least absolute deviation method predicts the <strong>median</strong> of $y$. The mean and median are generally not the same. For example, if the data values are 0 and 2, the least squares method predicts 1 as the forecast value, while the least absolute deviation method predicts a random number between 0~2 as the forecast value.</li><li><strong>Ease of Derivation</strong>: For the least squares method, since the optimization problem is to minimize the sum of squared errors, the problem can be solved by linear algebra. However, for the least absolute deviation method, the target is to minimize the sum of absolute errors, which is not differentiable at certain points, making the derivation process more complicated. Also, because the absolute values can introduce a subgradient, the solution process becomes even more challenging.</li><li><strong>Excellent Statistical Properties</strong>: If the error term satisfies a normal distribution, the least squares method can maximize the likelihood function (MLE), meaning it is the best linear unbiased estimator (BLUE).</li></ul><p>However, the primary reason why the least absolute deviation method is not widely used is due to a significant disadvantage of the least squares method: <strong>Vulnerability to Outliers</strong>.</p><p>The least squares method is easily influenced by outliers. Therefore, when comparing predicted values with real-world data that contains outliers, the least squares method often deviates significantly. Adjusting the weights of outliers can alleviate the issue, but in extreme cases, the least absolute deviation method is still more robust in dealing with outliers.</p><p>In summary, while the least squares method produces accurate and reliable predictions in most scenarios, it may perform poorly when there are outliers in the data. <strong>In cases where outliers are present, the least squares method is not an ideal choice.</strong></p><h5 id=023-bayesian-lr-and-ols>0.2.3 Bayesian LR and OLS</h5><p>The relationship between Bayesian linear regression and the ordinary least squares (OLS) method for solving linear regression?</p><ul><li>If we assume a non-informative prior for $\beta$ and use the posterior mode as the point estimate, the result will be identical to the OLS regression outcome.</li><li>If the prior for $\beta$ follows a Laplace distribution, the estimation result corresponds to the LASSO regression, where the regularization coefficient is related to the parameters of the Laplace distribution.</li><li>If the prior for $\beta$ follows a normal distribution, the estimation result corresponds to Ridge regression, where the regularization coefficient is related to the parameters of the normal distribution.</li></ul><p>For a non-informative prior on the parameters, it essentially means we impose no restrictions on the parameters, resulting in the same outcome as OLS.</p><p>However, if we assume that the parameters follow a certain distribution, it is equivalent to imposing some restrictions on them, and the results obtained in this case are akin to being adjusted through certain regularization techniques.</p><p>With reference to <a href=https://zhuanlan.zhihu.com/p/86009986 target=_blank rel=noopener>here</a></p><h5 id=024-when-will-overliney--overlinehaty>0.2.4 When will $\overline{y} = \overline{\hat{y}}$?</h5><p>Rewrite the condition of the question, we can get: $\frac{1}{n}\boldsymbol{1}^\top Y=\frac{1}{n}\boldsymbol{1}^\top\hat{Y}$, which is equivalent to $\boldsymbol{1}^\top(Y-\hat{Y})=0$.</p><p>We can prove that $\boldsymbol{X}^\top(Y-\hat{Y})=0$:
$$
\hat{\boldsymbol{Y}}=\boldsymbol{X}\hat{\boldsymbol{\beta}} = \boldsymbol{X}(\boldsymbol{X}^\top\boldsymbol{X})^{-1}\boldsymbol{X}^\top \boldsymbol{Y}
$$</p><p>Multiple $\boldsymbol{X}^\top$ on the left:
$$
\boldsymbol{X}^\top\hat{\boldsymbol{Y}}=\boldsymbol{X}^\top \boldsymbol{Y} \Rightarrow \boldsymbol{X}^\top (\boldsymbol{Y} - \hat{\boldsymbol{Y}}) = 0
$$</p><p>So if $\boldsymbol{X}$ contains a colume vector like $\boldsymbol{1}$, an intercept term, $\overline{y} = \overline{\hat{y}}$.</p><p>While sometime LR does not contain an intercept term, so the answer is $rank(\boldsymbol{X},\boldsymbol{1})=rank(\boldsymbol{X})$ (assume $n>p$).</p></div><div class="row ps-3 pe-3"><div class="col-md-6 share-buttons"><strong>Share on:</strong>
<a class="btn icon-button bg-facebook" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_conceptions%2f" target=_blank><i class="fab fa-facebook"></i>
</a><a class="btn icon-button bg-twitter" href="https://twitter.com/share?url=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_conceptions%2f&text=Questions%20of%20Conceptions&via=Haohan%27s%20Blog" target=_blank><i class="fab fa-twitter"></i>
</a><a class="btn icon-button bg-reddit" href="https://reddit.com/submit?url=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_conceptions%2f&title=Questions%20of%20Conceptions" target=_blank><i class="fab fa-reddit"></i>
</a><a class="btn icon-button bg-linkedin" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_conceptions%2f&title=Questions%20of%20Conceptions" target=_blank><i class="fab fa-linkedin"></i>
</a><a class="btn icon-button bg-whatsapp" href="https://api.whatsapp.com/send?text=Questions%20of%20Conceptions https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_conceptions%2f" target=_blank><i class="fab fa-whatsapp"></i>
</a><a class="btn icon-button" href="mailto:?subject=Questions%20of%20Conceptions&body=https%3a%2f%2fonline727.github.io%2fposts%2flinear_models%2flr_quant%2flr_conceptions%2f" target=_blank><i class="fas fa-envelope-open-text"></i></a></div><div class="col-md-6 btn-improve-page"><a href=https://github.com/online727/online727.github.io/edit/main/content/posts/linear_models/lr_quant/lr_conceptions/index.md title="Improve this page" target=_blank rel=noopener><i class="fas fa-code-branch"></i>
Improve this page</a></div></div><hr><div class="row next-prev-navigator"><div class="col-md-6 previous-article"><a href=/posts/linear_models/lr/ title="Linear Regression" class="btn filled-button"><div><i class="fas fa-chevron-circle-left"></i> Prev</div><div class=next-prev-text>Linear Regression</div></a></div><div class="col-md-6 next-article"><a href=/posts/linear_models/lr_quant/lr_assumptions/ title="Questions of Assumptions" class="btn filled-button"><div>Next <i class="fas fa-chevron-circle-right"></i></div><div class=next-prev-text>Questions of Assumptions</div></a></div></div><hr></div></div></div><a id=scroll-to-top class=btn type=button data-bs-toggle=tooltip data-bs-placement=left title="Scroll to top"><i class="fas fa-chevron-circle-up"></i></a></section><section class=toc-section id=toc-section><div class=toc-holder><h5 class="text-center ps-3">Table of Contents</h5><hr><div class=toc><nav id=TableOfContents><ul><li><a href=#01-notations>0.1 Notations</a></li><li><a href=#02-conceptions-and-basic-definitions>0.2 Conceptions and Basic Definitions</a><ul><li><ul><li><ul><li><a href=#021-the-assumptions-of-lr>0.2.1. The assumptions of LR</a></li><li><a href=#022-the-loss-function-of-lr-and-why-we-choose-it>0.2.2 The loss function of LR and why we choose it?</a></li><li><a href=#023-bayesian-lr-and-ols>0.2.3 Bayesian LR and OLS</a></li><li><a href=#024-when-will-overliney--overlinehaty>0.2.4 When will $\overline{y} = \overline{\hat{y}}$?</a></li></ul></li></ul></li></ul></li></ul></nav></div></div></section></div><footer id=footer class="container-fluid text-center align-content-center footer pb-2"><div class="container pt-5"><div class="row text-start"><div class="col-md-4 col-sm-12"><h5>Navigation</h5><ul><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#about>About</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#education>Education</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#experiences>Experiences</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#projects>Projects</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#skills>Skills</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#featured-posts>Featured Posts</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#recent-posts>Recent Posts</a></li><li class=nav-item><a class=smooth-scroll href=https://online727.github.io/#accomplishments>Accomplishments</a></li></ul></div><div class="col-md-4 col-sm-12"><h5>Contact me:</h5><ul><li><a href=mailto:zhhohoh27@gamil.com target=_blank rel=noopener><span><i class="fas fa-envelope"></i></span> <span>zhhohoh27@gamil.com</span></a></li><li><a href=https://github.com/online727 target=_blank rel=noopener><span><i class="fab fa-github"></i></span> <span>online727</span></a></li><li><a href=https://www.linkedin.com/in/haohan-zhao-9a6b24296 target=_blank rel=noopener><span><i class="fab fa-linkedin"></i></span> <span>Haohan Zhao</span></a></li><li><span><i class="fas fa-phone-alt"></i></span> <span>+86 19551998168</span></li></ul></div></div></div><hr><div class=container><p id=disclaimer><strong>Liability Notice:</strong> This site is built on hugo and github pages and uses the hugo-toha theme. The site is used for personal blogging, all content is owned by me and does not constitute any relevant advice, if you have any questions, please contact me!</p></div><hr><div class=container><div class="row text-start"><div class=col-md-4><a id=theme href=https://github.com/hugo-toha/toha target=_blank rel=noopener><img src=/images/theme-logo_hu16779671404603505019.png alt="Toha Theme Logo">
Toha</a></div><div class="col-md-4 text-center">© 2020 Copyright.</div><div class="col-md-4 text-end"><a id=hugo href=https://gohugo.io/ target=_blank rel=noopener>Powered by
<img src=/images/hugo-logo.svg alt="Hugo Logo" height=18></a></div></div></div></footer><script src=/application.aa1b29568827d862abc07cd2a25fa9f3f1dad96fd8fe2a012bccae2de39367fc.js integrity="sha256-qhspVogn2GKrwHzSol+p8/Ha2W/Y/ioBK8yuLeOTZ/w=" defer></script></body></html>